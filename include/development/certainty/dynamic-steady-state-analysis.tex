Dynamic steady-state analysis addresses the shortcomings of static steady-state
analysis in one particular but important context. It tackles the scenario where
the power consumption follows a certain periodic pattern. In this case, after a
sufficiently long time, the system will not reach a static steady state but
instead a dynamic steady state: temperature will starts to exhibit a periodic
patter following the periodic patter of power. Then the goal of the analysis is
to find the periodic temperature profile \mq, called the dynamic steady-state
temperature profile, that corresponds to a given periodic power profile \mp.

\subsection{Motivation}

In the case of applications that exhibit periodic or close to periodic behavior
(or which are characterized by several operation modes, each of which exhibits a
periodic behavior), the SSDTP is of particular importance for system design. Any
design optimization has to be performed such that the efficiency and reliability
of the system are maximized considering not a very short transient time interval
at system start (or mode setup) but the context in which the system functions
over a long period of time.

A typical design task, for which the SSDTP is of central importance, is
temperature-aware reliability optimization. The impact of temperature on the
lifetime of electronic circuits is well-known \cite{srinivasan2004, coskun2006,
xiang2010, jedec2010}. The failure mechanisms commonly considered are
electromigration, time-dependent dielectric breakdown, and thermal cycling,
which are directly driven by the temperature \cite{jedec2010}. What is important
in this context is that not only average and maximum temperature, but also the
amplitude and frequency of temperature oscillations, have a huge impact on the
overall lifetime of the chip. Thus, efficient reliability optimization depends
on the availability of the actual SSDTP.

Two approaches have been applied in the literature in order to obtain the SSDTP,
as a prerequisite for reliability optimization. An approximate SSDTP can be
produced by running a temperature simulator over one or more successive periods
of the application until one can assume that a sufficient approximation of the
thermal steady state has been reached \cite{srinivasan2004}. Such an approach is
both time consuming and potentially inaccurate. A very rough but fast
approximation of the SSDTP is proposed in \cite{huang2009}. It constructs a
stepwise temperature curve where each step corresponds to the static
steady-state temperature that would be reached if a certain constant power was
applied for a sufficiently long time. In \sref{hotspot-solution} we will further
elaborate on these two state of the art solutions. As our experiments show, they
are too slow and/or too inaccurate in order to efficiently be used inside a
temperature-aware system-level optimization loop for, e.g., reliability
optimization.

In this paper we consider multiprocessor systems running applications exhibiting
a power profile that can be considered periodic. Our contribution is twofold.
First, we propose an approach that is both accurate and fast, for SSDTP
calculation. Second, we show how our approach makes it possible to efficiently
perform reliability optimization, based on the thermal cycling (TC) failure
mechanism. More exactly, we propose a temperature-aware task mapping and
scheduling technique that addresses the TC ageing effect. Experiments
demonstrate the superiority of the proposed techniques, compared to the state of
the art.

\subsection{Prior Work}
\slab{hotspot-solution}
\slab{hotspot-iterative-solution}
\slab{steady-state-approximation}

The TTA using the analytical technique given in \eref{recurrence-original} can
be employed to approximate the SSDTP by applying it over successive application
periods, as shown in \sref{hotspot-iterative-solution}. Since each iteration,
with this approach, is much faster than with HotSpot, it will significantly
speed up the SSDTP calculation. However, the number of required iterations is
similar to the case when HotSpot is used (see \fref{hotspot-error}), still
keeping the computational process slow (\sref{results-ssdtp}).

A rough approximation of the SSDTP can be obtained by running a temperature
simulation over successive periods of the application until it can be assumed
that the system has reached the thermal steady state. The simulator performs the
transient temperature analysis where the common approach is to solve
\eref{temperature-model-original} numerically, for instance, using the
fourth-order Runge-Kutta method \cite{press2007}.

The number of iterations required to reach the SSDTP depends on the thermal
characteristics of the system. In order to illustrate this aspect, we have
considered an application with the period of 0.5 $s$ running on five
hypothetical platforms with core areas between 1 and 25 $mm^2$. The
configuration of the die and thermal package can be found in the appendix
(\tref{parameters}). We have run the temperature simulation with HotSpot
\cite{skadron2003} for 50 successive periods. The temperature profile in each
period has been compared with the actual SSDTP, obtained with our analytical
approach (\sref{condensed-equation}), and the normalized root mean square error
(NRMSE) has been calculated. The result is shown in \fref{hotspot-error}. It can
be observed that the number of successive periods over which the temperature
simulation has to be performed, in order to achieve a satisfactory level of
accuracy, is significant for the majority of configurations. For a 9 $mm^2$ die,
for example, after 15 iterations, the NRMSE is still close to 20\%. This leads
to large computation times, making it difficult to apply the technique inside an
intensive optimization loop.

HotSpot \cite{skadron2003}, an architecture and system-level model and
simulator, is the state of the art choice for system-level temperature analysis,
as in \cite{srinivasan2004, liao2005, coskun2006, liu2007, huang2009, xiang2010,
thiele2011}.

An approximation of the SSDTP has been proposed in \cite{huang2009}. Instead of
solving the system of equations in \eref{temperature-model-original}, it is
assumed that during each time interval $\Delta t_i$, in which the power is
constant, the system stays in its steady state. The result is a stepwise
temperature curve where each step corresponds to the steady-state temperature
$\v{T}_i$ that would be reached if the constant power $\v{P}_i$ was applied for
a sufficiently long time.

An example of such an approximation (SSA) along with the corresponding SSDTP for
an application with 10 tasks and period of 0.1 $s$ is given in
\fref{steady-state-approximation}. The die area is 25 $mm^2$, the configuration
of the chip is the same as in \tref{parameters}. The reduced accuracy of the SSA
is due to the mismatch between the actual temperature within each interval
$\Delta t_i$ and the hypothetical steady-state temperature. The inaccuracy
depends on the thermal characteristics of the respective platform and on the
application itself. To illustrate this, we have generated five applications with
periods between 0.01 and 1~$s$ and computed approximated SSDTPs using the SSA
for die areas between 1 and 25 $mm^2$. The NRMSE relative to the correct SSDTP
is shown in \fref{steady-state-error}. It can be seen that, e.g., for a die area
of 10 $mm^2$ and a period of $100~ms$ the NRMSE with the SSA is close to 40\%.

\subsection{Our Solution}
\slab{condensed-equation}
\slab{straight-forward}

As shown in \sref{hotspot-solution}, the state of the art solutions either
produce inaccurate and, in many cases, completely useless results, or they are
unacceptably slow. In this section we eliminate the first problem by obtaining
an analytical solution for the SSDTP and tackle the second one in
\sref{condensed-equation} where a fast solution technique is proposed.

For the SSDTA calculation the following system of linear equations can be
derived from \eref{recurrence-original}:
\[
  \begin{cases}
    \m{K}_0 \: \v{T}_0 - \v{T}_1 & = -\m{B}_0 \: \v{P}_0 \\
    ... \\
    -\v{T}_0 + \m{K}_{N_s - 1} \: \v{T}_{N_s - 1} & = -\m{B}_{N_s - 1} \: \v{P}_{N_s - 1}
  \end{cases}
\]
where the last equation enforces the boundary condition, the equality of
temperature values on both ends of the period:
\begin{equation} \elab{boundary-condition}
  \v{T}_0 = \v{T}_{N_s}
\end{equation}
To get the whole picture, the system can be written as:
\begin{equation} \elab{system}
\resizebox{0.9\linewidth}{!}{
  $\underbrace{\left[
    \begin{array}{ccccc}
      \m{K}_0 & -\m{I} & 0 & \cdots & 0 \\
      0 & \m{K}_1 & -\m{I} &  & \vdots \\
      \vdots &  & \ddots & -\m{I} & 0 \\
      0 &  &  & \m{K}_{N_s - 2} & -\m{I} \\
      -\m{I} & 0 & \cdots & 0 & \m{K}_{N_s - 1}
    \end{array}
  \right]}_{\displaystyle \mathbb{A}} \underbrace{\left[
    \begin{array}{c}
      \v{T}_0 \\
      \\
      \vdots \\
      \\
      \v{T}_{N_s - 1}
    \end{array}
  \right]}_{\displaystyle \mathbb{X}} = \underbrace{\left[
    \begin{array}{c}
      -\m{B}_0 \: \v{P}_0 \\
      \\
      \vdots \\
      \\
      -\m{B}_{N_s - 1} \: \v{P}_{N_s - 1}
    \end{array}
  \right]}_{\displaystyle \mathbb{B}}$
}
\end{equation}
where $\mathbb{A}$ is a $N_n N_s \times N_n N_s$ matrix, $\mathbb{X}$ and
$\mathbb{B}$ are vectors with $N_n N_s$ elements. It can be seen that we have
obtained a regular system of linear equations.

Straight-forward techniques to solve it and their disadvantages are further
discussed now.

The first straight-forward way to solve the system in \eref{system} is to use
dense solvers such as the LU decomposition \cite{press2007}. However, a more
advanced approach is to employ sparse solvers since the matrix of the system is
a sparse matrix. Therefore, algorithms specially designed for such cases are
preferable, e.g., the unsymmetric multifrontal method \cite{davis2004}. The
computational complexity of the solution is proportional to $N_s^3 N_n^3$
\cite{press2007} where $N_n$ is the number of nodes and $N_s$ is the number of
steps in the power profile. The problem here is that the systems to solve can be
extremely large, in particular due to $N_s$. Our experiments have shown that
direct solvers are extremely slow and consume a large amount of memory.
Therefore, we do not consider them in the paper.

The overall matrix of the system in \eref{system} is, in fact, a block Toeplitz
matrix. To be more specific, the matrix is a block-circulant matrix where each
block row vector is rotated one block element to the right relative to the
preceding block row vector. This leads to a wide range of possible techniques to
solve the system, e.g., the fast Fourier transform (FFT) \cite{mazancourt1983}
that we include in our experiments in \sref{results-ssdtp}.

Another possible technique is iterative methods for solving systems of linear
equations (e.g., Jacobi, Gauss--Seidel, Successive Overrelaxation)
\cite{press2007}. These methods are designed to overcome problems of direct
solvers and, consequently, they are applicable for very large systems. However,
the most important issue with these methods is their convergence. In our
experiments we did not observe any advantages of using these methods compared to
the others considered in this paper. Therefore, they are excluded from the
discussion.

In this section we propose a fast approach to solve the system in \eref{system}.
The approach consists of an auxiliary transformation (\sref{substitution}) and
the actual solution (\sref{condensed-equation}).

The major problem with straight-forward techniques is that (1) the sparseness of
the matrix is not taken into account and/or (2) its specific structure is
totally ignored, resulting in inefficiency and inaccuracy of the computations.
Using direct dense and sparse solvers, for example, requires a computation time
proportional to $N_n^3 N_s^3$ \cite{press2007}. Our proposed technique considers
both features and delivers solutions in time proportional to $N_s N_n^3$ while
operating only on a few $N_n \times N_n$ matrices. It is important that the
dependency on $N_s$ (the number of steps in the power profile), which is by far
dominating ($N_s \gg N_n$), is linear.

Observing the structure of the matrix in \eref{system}, non-zero elements are
located only on the block diagonal, on one subdiagonal just above the block
diagonal, and on one subdiagonal in the left bottom corner. The block diagonal
is composed of $N_n \times N_n$ matrices while all elements of the subdiagonals
are equal to $-1$. Linear systems with the same structure arise in boundary
value problems for ODEs where a technique to solve them is to form a so-called
condensed equation (CE), or condensed system \cite{stoer2002}.

In the recurrence given by \eref{recurrence} we denote $\m{Q}_i = \tm{B}_i \:
\v{P}_i$:
\begin{align}
  & \tv{T}_{i + 1} = \tm{K}_i \: \tv{T}_i + \m{Q}_i, \; i = \range{0}{N_s - 1} \elab{ce-recurrent} \\
  & \tv{T}_0 = \tv{T}_{N_s} \nonumber
\end{align}
Performing the iterative repetition of \eref{ce-recurrent} leads to:
\begin{equation} \elab{y-recurrent}
  \tv{T}_i = \prod_{j = 0}^{i - 1} \tm{K}_j \: \tv{T}_0 + \m{W}_{i - 1}, \; i = \range{1}{N_s}
\end{equation}
where $\m{W}_i$ are defined as follows:
\begin{equation}
  \m{W}_0 = \m{Q}_0 \hspace{15pt} \m{W}_i = \tm{K}_i \: \m{W}_{i - 1} + \m{Q}_i, \; i = \range{1}{N_s - 1} \elab{p-recurrent}
\end{equation}
We calculate the final vector $\tilde{\v{T}}_{N_s}$ using \eref{y-recurrent} and
\eref{p-recurrent}:
\[
  \tilde{\v{T}}_{N_s} = \prod_{j = 0}^{N_s - 1} \tilde{\m{K}}_j \: \tilde{\v{T}}_0 + \m{W}_{N_s - 1}
\]
Taking into account the boundary condition given by \eref{boundary-condition},
we obtain the following system of linear equations:
\begin{equation} \elab{core-system}
  (\m{I} - \prod_{j = 0}^{N_s - 1} \tm{K}_j) \: \tv{T}_0 = \m{W}_{N_s - 1}
\end{equation}
We recall that $\tm{K}_i$ is the matrix exponential given by
\eref{matrix-exponential}; therefore, the following simplification holds:
\[
  \prod_{j = i}^l \tm{K}_j = \prod_{j = i}^l e^{\tm{A} \Delta t_j} = e^{\tm{A} \sum_{j = i}^l \Delta t_j} = \m{U} e^{\left( \sum_{j = i}^l \Delta t_j \: \m{\Lambda} \right)} \m{U}^T
\]
Consequently:
\[
  \prod_{j = 0}^{N_s - 1} \tm{K}_j = \m{U} \: \diagonal{e^{\tau \lambda_0}}{e^{\tau \lambda_{N_n - 1}}} \: \m{U}^T
\]
where $\tau$ is the application period. Substituting this product into
\eref{core-system}, we obtain the following system:
\[
  (\m{I} - \m{U} \: e^{\tau \m{\Lambda}} \: \m{U}^T) \: \tv{T}_0 = \m{W}_{N_s - 1}
\]
The identity matrix $\m{I}$ can be split into $\m{U} \m{U}^T$, hence:
\begin{equation} \elab{t0}
  \tv{T}_0 = \m{U} \: (\m{I} - e^{\tau \m{\Lambda}})^{-1} \: \m{U}^T \: \m{W}_{N_s - 1} = \m{Z} \: \m{W}_{N_s - 1}
\end{equation}
where:
\[
  \m{Z} = \m{U} \: \diagonal{\frac{1}{1 - e^{\tau \lambda_0}}}{\frac{1}{1 - e^{\tau \lambda_{N_n - 1}}}} \: \m{U}^T
\]
The equation gives the initial solution vector $\tv{T}_0$; the rest of vectors
$\tv{T}_i$ for $i = \range{1}{N_s - 1}$ are successively found from
\eref{ce-recurrent}.

Since the power profile is evenly sampled with the sampling interval $\Delta t$,
the recurrence in \eref{ce-recurrent} turns into:
\[
  \tv{T}_{i+1} = \tm{K} \: \tv{T}_i + \m{Q}_i = \tm{K} \: \tv{T}_i + \tm{B} \: \v{P}_i
\]
where $\tm{K} = e^{\tm{A} \: \Delta t}$ and $\tm{B} = \tm{A}^{-1} ( e^{\tm{A} \:
\Delta t} - \m{I} ) \m{C}^{-\frac{1}{2}}$. Here $\tm{K}$ and $\tm{B}$ are
constants, since they depend only on the matrices $\tm{A}$, $\m{C}$, and
sampling interval $\Delta t$, which is fixed. In this case, the block diagonal
of the matrix $\tilde{\mathbb{A}}$, similar to \eref{system}, is composed of the
same repeating block $\tm{K}$ and the recurrent expressions take the following
form:
\begin{align}
  & \m{W}_i = \tm{K} \: \m{W}_{i - 1} + \m{Q}_i, \; i = \range{1}{N_s - 1} \elab{final-p-recurrence} \\
  & \tv{T}_{i + 1} = \tm{K} \: \tv{T}_i + \m{Q}_i, \; i = \range{0}{N_s - 1} \elab{final-y-recurrence}
\end{align}
where $\m{Q}_i = \tm{B} \: \v{P}_i$, $\m{W}_0 = \m{Q}_0$, and $\tv{T}_0$ is
given by \eref{t0}.

The last step of the solution is to return to temperature by performing the
backward substitution opposite to \eref{substitution}:
\[
  \v{T}_i = \m{C}^{-\frac{1}{2}} \: \tv{T}_i, \: i = \range{0}{N_s - 1}
\]

As we see, the auxiliary substitution from \sref{substitution} allows us to
perform the single-time eigenvalue decomposition with orthogonal eigenvectors
that later eases the computational process at several stages. In
\sref{condensed-equation} it can be observed that the solution of the system in
\eref{system} has been reduced to two successive recurrences in
\eref{final-p-recurrence} and \eref{final-y-recurrence} over $N_s$ steps in the
power profile, which implies a linear complexity on $N_s$ mentioned earlier.

It should be noted that the eigenvalue decomposition along with matrices
$\tm{K}$ and $\tm{B}$ are computed only once for a particular RC thermal circuit
and can be considered as given together with the RC circuit. It has not to be
recalculated when a SSDTP is generated, which significantly decreases the
computation time.

\subsection{Leakage Power}

So far, we have assumed that power is independent of temperature. However, due
to the leakage component, the power dissipation is a strong function of
temperature that cannot be neglected (\sref{power-model}). Two techniques can be
applied to include in our proposed solution temperature-dependent leakage
modeling.

\subsubsection{Iterative Computation}
\slab{iterative-leakage}

In this case, we have an iterative process, depicted in \fref{leakage}, where
the temperature and power profiles are calculated in turns. With each new
temperature profile we update the power profile by computing the leakage power
and adding it to the dynamic power: $\mathbb{P}_i = \mathbb{P}_\text{dyn} +
\mathbb{P}_\text{leak}(\mathbb{T}_i)$. The process continues until the
temperature converges, i.e., the difference between two successive temperature
profiles is below a predefined bound. In our experiments we used $0.5^\circ C$
as the maximal acceptable difference and observed that the number of required
iterations to converge is 4--7.

\subsubsection{Linear Approximation}
\slab{linearized-leakage}

A linear approximation of the leakage power has the following matrix form:
$\v{P}_\text{leak}(\v{T}) = \m{A} \: \v{T}(t) + \v{B}$ where $\m{A}$ is a $N_n
\times N_n$ diagonal matrix of the proportionality and $\v{B}$ is a vector with
$N_n$ elements of the intercept. Both characterize the leakage power for each of
the $N_n$ thermal nodes in the system. It can be seen that the approximation
keeps \eref{temperature-model-original} untouched: $\m{C} \:
\frac{d\v{T}(t)}{dt} + \bar{\m{G}} \: (\v{T}(t) - \v{T}_\ambient) = \bar{\v{P}}$
where $\bar{\m{G}} = \m{G} - \m{A}$ and $\bar{\v{P}} = \v{P}_\text{dyn} + \m{A}
\: \v{T}_\ambient + \v{B}$. Therefore, all solutions proposed in this paper are
perfectly valid with the linearized model. Moreover, in spite of its simplicity,
the model provides a good estimation, as shown in \cite{liu2007}.

In order to evaluate the linearization, we have constructed a number of
hypothetical platforms with 2--32 cores (other parameters are given in
\tref{parameters}) and compared temperature profiles obtained with the
linearization and the exponential model (\sref{power-model}), respectively. For
the later, we use the iterative approach described in \sref{iterative-leakage}.
For the linearization, the power curve fitting with the least squares regression
\cite{press2007} has been employed, targeted at the range between 40 and
$80^\circ C$. From the experiments we have observed that the NRMSE is bounded by
1--2\%, indicating a good accuracy of the linear approximation.
