Dynamic steady-state analysis addresses the shortcomings of static steady-state
analysis in one particular but important context. It tackles the scenario where
the power consumption follows a periodic pattern. In this case, after a
sufficiently long time, the system will not reach a static steady state but
instead a dynamic steady state: temperature will starts to exhibit a periodic
patter following the periodic patter of power. Then the goal of the analysis is
to find the periodic temperature profile \mq, called the dynamic steady-state
temperature profile (\up{DSSTP}), that corresponds to a given periodic power
profile \mp.

In the case of applications that exhibit periodic or close to periodic behavior,
the \up{DSSP} is of particular importance. Any design optimization has to be
performed such that the efficiency and reliability of the system at hand are
maximized considering not a relatively short transient time interval at the
system's start but the context in which the system is to function over a long
period of time, which is exactly the system's dynamic steady state.

A typical design task, for which the \up{DSSTP} is of central importance, is
temperature-aware reliability optimization. The impact of temperature on the
lifetime of electronic systems is well known \cite{srinivasan2004, coskun2006,
jedec2010, xiang2010}. The failure mechanisms commonly considered are
electromigration, time-dependent dielectric breakdown, and thermal cycling,
which are directly driven by temperature \cite{jedec2010}. What is important in
this context is that not only the average and maximum temperature have a huge
impact on the lifetime of the chip but also the amplitude and frequency of
temperature oscillations. Thus, efficient reliability optimization depends on
the availability of the actual \up{DSSTP}.

\subsection{Prior Work}
\slab{dynamic-steady-state-prior}

Let us elaborate on the techniques that have been applied in the literature in
order to compute the \up{DSSTP} as a prerequisite for reliability optimization.

A straightforward approximation of the \up{DSSTP} can be obtained by running a
temperature simulator over one or more successive periods of the application
until it is assumed that a sufficiently accurate approximation of the dynamic
steady state has been attained \cite{srinivasan2004}. The typical simulator of
choice is HotSpot \cite{skadron2003}, which is the state-of-the-art for
system-level temperature analysis \cite{srinivasan2004, liao2005, coskun2006,
liu2007, huang2009, xiang2010, thiele2011}. The simulator performs transient
temperature analysis by solving \eref{temperature-model-original} numerically
via the Runge--Kutta fourth-order method \cite{press2007}.

\inputfigure{dynamic-steady-state-prior}
The number of iterations required to reach the \up{DSSTP} depends on the thermal
characteristics of the platform. In order to illustrate this aspect, consider an
application with a period of 0.5~s running on five hypothetical platforms with
die areas of 1--25~mm\textsuperscript{2}. Let us simulate 50 successive periods
of the application via HotSpot with its default settings and compare the
resulting approximations in each period with the actual \up{DSSTP} using the
normalized root-mean-square error (\up{NRMSE}). The comparison is shown in
\fref{iterative-transient-error}. It can be observed that the number of
successive periods over which transient analysis has to be performed in order to
achieve a satisfactory level of accuracy is significant for the majority of the
configurations, which entails large computation times. For instance, for a
9-mm\textsuperscript{2} die, even after 15 iterations, the \up{NRMSE} is still
close to 20\%. Using the analytical approach to transient analysis presented in
\sref{transient-analysis}, the calculation can be sped up; however, the large
number of iterations still keeps the computation cost unreasonably high as we
shall illustrate in \sref{dynamic-steady-state-results}. Moreover, this
approximation technique provides no guarantees on the resulting accuracy since
there is no a reliable metric for measuring the proximity to the actual
solution, that is, to the actual \up{DSSTP}.

Another crude but fast approximation of the \up{DSSTP} is proposed in
\cite{huang2009}. It forgoes transient analysis all together and resides to
static steady-state analysis instead. To elaborate, it is assumed that, in each
time interval wherein the power consumption is constant, the system
instantaneously reaches a static steady state. The result of this procedure is a
stepwise temperature curve where each step corresponds to the steady-state
temperature that would be reached if the corresponding power was applied for a
sufficiently long time.

\inputfigure{static-steady-state-example}
An example of such an approximation along with the corresponding \up{DSSTP} for
an application with 10 tasks and a period of 0.1~s is given in
\fref{static-steady-state-example}. The die area is 25~mm\textsuperscript{2} in
this case. The reduced accuracy of this technique is due to the mismatch between
the actual temperature within each interval and the static steady-state
temperature. The inaccuracy depends on the thermal characteristics of the
platform and on the application itself. In order to illustrate this concern, let
us simulate five applications with periods of 0.01--1~s running on five
platforms with die areas of 1--25~mm\textsuperscript{2} and assess the resulting
profiles. The errors relative to the actual \up{DSSTP}s are shown in
\fref{static-steady-state-error}. It can be seen that, for example, for a die
area of 10~mm\textsuperscript{2} and an application period of 100~ms, the
\up{NRMSE} of this approximation technique is close to 40\%.

To conclude, the state-of-the-art techniques for dynamic steady-state
temperature analysis are slow and inaccurate. This state of affairs makes them
difficult and dangerous to be utilized for the purpose of design optimization.

\subsection{Our Solution}
\slab{dynamic-steady-state-present}

In this subsection, we are to formalize the problem of dynamic steady-state
temperature analysis and to develop an exact and, moreover, computationally
efficient solution to this problem, eliminating the issues of the
state-of-the-art solutions discussed in the previous subsection.

Consider the temperature model in \eref{temperature-model} and the corresponding
recurrence in \eref{recurrence}. The key characteristic of a dynamic steady
state is as follows:
\begin{equation} \elab{boundary-condition}
  \vs_0 = \vs_\ns.
\end{equation}
In words, the above condition means that, once the steady state has been
reached, the system starts to arrive at its initial state at the end of each
iteration, which is what makes it periodic. Then, using \eref{recurrence}, the
\up{DSSTP} can be computed by solving the following system of linear equations:
\[
  \begin{cases}
    \vs_1 - \m{E} \vs_\ns & = \m{F}_1 \vp_1 \\
    \dots \\
    \vs_\ns - \m{E}_\ns \vs_{\ns - 1} & = \m{F}_\ns \vp_\ns
  \end{cases}
\]
where the first equation enforces the boundary condition in
\eref{boundary-condition}. In order to get the big picture, the system can be
rewritten as follows:
\begin{equation} \elab{steady-state-system}
  \resizebox{0.89\linewidth}{!}{
    $\underbrace{\left[
      \begin{array}{rrrrrrr}
        \m{I}  &  0     & 0      & \cdots & 0      & 0      & -\m{E} \\
        -\m{E} & \m{I}  & 0      & \cdots & 0      & 0      & 0      \\
        0      & -\m{E} & \m{I}  & \cdots & 0      & 0      & 0      \\
        \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\
        0      & 0      & 0      & \cdots & \m{I}  & 0      & 0      \\
        0      & 0      & 0      & \cdots & -\m{E} & \m{I}  & 0      \\
        0      & 0      & 0      & \cdots & 0      & -\m{E} & \m{I}
      \end{array}
    \right]}_{\displaystyle \mathbb{A}} \underbrace{\left[
      \begin{array}{l}
        \vs_1         \\
        \vs_2         \\
        \vs_3         \\
        \cdots        \\
        \vs_{\ns - 2} \\
        \vs_{\ns - 1} \\
        \vs_\ns
      \end{array}
    \right]}_{\displaystyle \mathbb{X}} = \underbrace{\left[
      \begin{array}{l}
        \m{F} \vp_1         \\
        \m{F} \vp_2         \\
        \m{F} \vp_3         \\
        \cdots              \\
        \m{F} \vp_{\ns - 2} \\
        \m{F} \vp_{\ns - 1} \\
        \m{F} \vp_\ns
      \end{array}
    \right]}_{\displaystyle \mathbb{B}}$
  }
\end{equation}
where $\mathbb{A}$ is an $\nn \ns \times \nn \ns$ matrix, and $\mathbb{X}$ and
$\mathbb{B}$ are $\nn \ns$-element vectors.

The most direct way to solve the system in \eref{steady-state-system} is to use
a dense solver such as the \up{LU} decomposition \cite{press2007}. However,
since $\mathbb{A}$ is a sparse matrix, a more appropriate approach is to employ
a sparse solver such as the unsymmetric multifrontal method \cite{davis2004}.
The computational complexity of such solutions is proportional to $\ns^3 \nn^3$
\cite{press2007} where $\nn$ is the number of nodes in the thermal \up{RC}
circuit, and $\ns$ is the number of samples in the power profile. The problem
here is that the system to solve can be extremely large, in particular due to
$\ns$. In such cases, direct solvers are prohibitively slow and require an
enormous amount of memory. Therefore, we do not discuss them any further.

Another potential approach is leveraging an iterative method for solving systems
of linear equations such as the Jacobi or Gauss--Seidel method \cite{press2007}.
Such methods are designed to overcome problems of direct solvers, and,
consequently, they are applicable for very large systems. However, the most
important issue with these methods is their convergence. In our experiments, we
have not observed any advantages of using these methods compared to the other
considered techniques. Thus, they are excluded from the discussion.

Yet another solution can be obtain by observing that $\mathbb{A}$ in
\eref{steady-state-system} is, in fact, a block Toeplitz matrix and, moreover, a
block-circulant matrix, wherein each block row is rotated one block element to
the right relative to the preceding block row. This observation leads to a wide
range of possible techniques for solving the system in
\eref{steady-state-system} such as the fast Fourier transform
\cite{mazancourt1983}, which we shall discuss further in our experiments in
given \sref{dynamic-steady-state-results}.

To summarize, the major problem with the aforementioned techniques is that
\one~the sparseness of $\mathbb{A}$ is not taken into account, or \two~its
specific structure is ignored, resulting in inefficient and, in some cases,
inaccurate computations. Let us now develop a solution that does not have these
issues.

Have a careful look at the structure of $\mathbb{A}$ in
\eref{steady-state-system}. The nonzero elements are located only on the block
diagonal, on the subdiagonal attached to the block diagonal, and on the
superdiagonal in the top right corner of the matrix. Linear systems with similar
structures arise in boundary value problems for ordinary differential equations,
and the typical technique to solve them is to form a so-called condensed
equation or condensed system \cite{stoer2002} as follows.

To begin with, let
\[
  \v{v}_i = \m{F} \vp_i
\]
for $i = \range{1}{\ns}$. Equation~\eref{recurrence} can then be rewritten as
follows:
\begin{equation} \elab{steady-state-recurrence}
  \vs_i = \m{E} \vs_{i - 1} + \v{v}_i
\end{equation}
for $i = \range{1}{\ns}$. Apply this formula recursively starting from $\vs_0$
leads to
\[
  \vs_i = \m{E}^i \vs_0 + \v{w}_i
\]
for $i = \range{1}{\ns}$. In the above, $\v{w}_i$ is an auxiliary recurrence
defined as
\begin{equation} \elab{steady-state-auxiliary-recurrence}
  \v{w}_i = \m{E} \v{w}_{i - 1} + \v{v}_i
\end{equation}
for $i = \range{1}{\ns}$ where
\[
  \v{w}_0 = 0.
\]
After taking \ns steps, we arrive at the following state vector:
\[
  \vs_\ns = \m{E}^\ns \vs_0 + \v{w}_\ns.
\]
Taking into account the boundary condition given in \eref{boundary-condition},
we obtain the following system of linear equations:
\[
  (\m{I} - \m{E}^\ns) \vs_\ns = \v{w}_\ns.
\]
Since $\m{E}$ is the matrix exponential, which it can be seen in
\eref{matrix-exponential}, the above system can be rewritten as follows:
\[
  (\m{I} - \m{U} e^{\m{\Lambda} \tau} \m{U}^T) \vs_\ns = \v{w}_\ns
\]
where $\tau = \ns \dt$ is the period of the power profile \mp. By splitting the
identity matrix $\m{I}$ into $\m{U} \m{U}^T$, we obtain the following solution
to the system:
\begin{align}
  \vs_\ns
  & = \m{U} (\m{I} - e^{\m{\Lambda} \tau})^{-1} \m{U}^T \v{w}_\ns \elab{t0} \\
  & = \m{U} \: \diagonal{\frac{1}{1 - e^{\lambda_1 \tau}}}{\frac{1}{1 - e^{\lambda_\ns \tau}}} \m{U}^T \v{w}_\ns. \nonumber
\end{align}
The above equation yields not only the final state vector $\vs_\ns$ but also the
initial one $\vs_0$. Consequently, the rest of the state vectors $\{ \vs_i: i =
\range{1}{\ns - 1} \}$ can be successively found by means of
\eref{steady-state-recurrence} where each $\v{v}_i$ has already been calculated
when computing $\v{w}_\ns$. The last step of the solution process is to compute
the actual temperature profile \mq, the \up{DSSTP}, by applying
\eref{temperature-algebraic}.

It can be seen that the solution to the $\nn \ns \times \nn \ns$ system given in
\eref{steady-state-system} has been reduced to the two trivial recurrences given
in \eref{steady-state-recurrence} and \eref{steady-state-auxiliary-recurrence}
that traverse the \ns steps of the power profile \mp. Therefore, the
computational complexity of this process is linear with respect to \ns, which is
important since \ns is typically much large than \nn, that is, the number of
thermal nodes.

It is worth noting that the auxiliary transformation presented in
\sref{substitution} and the accompanying eigendecomposition in
\eref{eigendecomposition} have substantially simplified the calculations
associated with dynamic steady-state analysis. It should also be noted that the
eigendecomposition along with $\m{E}$ and $\m{F}$ are computed only once for a
particular thermal \up{RC} circuit and can be considered as given together with
the circuit. In other words, these quantities stay when different power profiles
are to be analyzed, which is particularly advantageous when an intensive
design-space-exploration procedure is concerned.

\subsection{Leakage Power}

So far, we have assumed that power is independent of temperature. However, due
to the leakage component, the power dissipation is a strong function of
temperature that cannot be neglected (\sref{power-model}). Two techniques can be
applied to include in our proposed solution temperature-dependent leakage
modeling.

\subsubsection{Iterative Computation}
\slab{iterative-leakage}

In this case, we have an iterative process, depicted in \fref{leakage}, where
the temperature and power profiles are calculated in turns. With each new
temperature profile we update the power profile by computing the leakage power
and adding it to the dynamic power: $\mathbb{P}_i = \mathbb{P}_\text{dyn} +
\mathbb{P}_\text{leak}(\mathbb{T}_i)$. The process continues until the
temperature converges, i.e., the difference between two successive temperature
profiles is below a predefined bound. In our experiments we used $0.5^\circ C$
as the maximal acceptable difference and observed that the number of required
iterations to converge is 4--7.

\subsubsection{Linear Approximation}
\slab{linearized-leakage}

A linear approximation of the leakage power has the following matrix form:
$\v{P}_\text{leak}(\v{T}) = \m{A} \: \v{T}(t) + \v{B}$ where $\m{A}$ is a $N_n
\times N_n$ diagonal matrix of the proportionality and $\v{B}$ is a vector with
$N_n$ elements of the intercept. Both characterize the leakage power for each of
the $N_n$ thermal nodes in the system. It can be seen that the approximation
keeps \eref{temperature-model-original} untouched: $\m{C} \:
\frac{d\v{T}(t)}{dt} + \bar{\m{G}} \: (\v{T}(t) - \v{T}_\ambient) = \bar{\v{P}}$
where $\bar{\m{G}} = \m{G} - \m{A}$ and $\bar{\v{P}} = \v{P}_\text{dyn} + \m{A}
\: \v{T}_\ambient + \v{B}$. Therefore, all solutions proposed in this paper are
perfectly valid with the linearized model. Moreover, in spite of its simplicity,
the model provides a good estimation, as shown in \cite{liu2007}.

In order to evaluate the linearization, we have constructed a number of
hypothetical platforms with 2--32 cores (other parameters are given in
\tref{parameters}) and compared temperature profiles obtained with the
linearization and the exponential model (\sref{power-model}), respectively. For
the later, we use the iterative approach described in \sref{iterative-leakage}.
For the linearization, the power curve fitting with the least squares regression
\cite{press2007} has been employed, targeted at the range between 40 and
$80^\circ C$. From the experiments we have observed that the NRMSE is bounded by
1--2\%, indicating a good accuracy of the linear approximation.

\subsection{Experimental Results}
\slab{dynamic-steady-state-results}

In this subsection we investigate the scaling properties of the proposed
solution for the SSDTP calculation and compare it with the approach based on the
TTA with HotSpot (\sref{dynamic-steady-state-prior})\footnote{All the
experiments are performed on a Linux machine with Intel\textregistered\
Core\texttrademark\ i7-2600 3.4GHz and 8Gb of RAM.}. We also include in the
comparison two additional techniques described in the appendix, namely the TTA
with the analytical solution (\sref{transient-analysis}) and the fast Fourier
transform (FFT) (\sref{straight-forward}). In the cases of the TTA, the
simulation over successive iterations is run until the NRMSE relative to the
SSDTP obtained with the proposed method is less than 1\%.

In the following experiments, the power sampling interval is set to 1 $ms$ and
the thermal configuration of the die is the same as in \tref{parameters}. For
the experiments in this subsection, the leakage power has not been considered.
If considered according to the linearized model (\sref{linearized-leakage}),
execution times remain unchanged; if considered according to the iterative model
(\sref{iterative-leakage}), execution times increase proportionally for all the
methods, which does not affect any of the conclusions.

First, we vary the application period $\tau$ keeping the architecture fixed,
which is a quad-core platform with the core area of 4 $mm^2$. The comparison is
depicted in \fref{scaling-time} on a semilogarithmic scale. It can be seen that
the proposed technique is roughly 5000 times faster than calculating the SSDTP
by running the TTA with HotSpot and from 9 to 170 times faster than the TTA with
the analytical solution.

In the second experiment we evaluate the scaling of the proposed method with
regard to the number of processing elements. The application period is fixed to
0.5 $s$. The results are shown in \fref{scaling-cores}. It can be observed that
the proposed technique provides a significant performance improvement relative
to the alternative solutions.
