Let $\L{2}{\Omega, \F, \probability}$ be as in \eref{square-integrable-space}.
Let also $G \subset \L{2}{\Omega, \F, \probability}$ be the Gaussian Hilbert
space \cite{janson1997} spanned by $n$ mutually independent standard Gaussian
random variables, which are denoted by $\vx: \Omega \to \real^n$. Since the
variables are independent and standard, they form an orthonormal basis in $G$,
and $G$ is $n$-dimensional. The variables induce a probability measure on
$\real^n$, and the corresponding distribution function $F$ is standard Gaussian
given by
\begin{equation} \elab{gaussian-measure}
  \d F(\v{y}) = (2 \pi)^{-\frac{n}{2}} \exp\left(-\frac{\norm[2]{\v{y}}^2}{2}\right) \d \v{y}.
\end{equation}
The inner product in the vector space of functions over $G$ is defined as
\begin{equation} \elab{chaos-inner-product}
  \innerproduct{g}{h} = \int_{\real^n} g(\v{y}) h(\v{y}) \d F(\v{y})
\end{equation}
for any $g$ and $h$ in this space, and the norm is defined as
\[
  \norm[2]{g} = \sqrt{\innerproduct{g}{g}}.
\]

Let $\Psi_\lc(G)$ be the space of $n$-variate polynomials over $G$ such that the
total order of each polynomial is at most $\lc \in \natural$. The space
$\Psi_\lc(G)$ can be constructed as a span of $n$-variate Hermite polynomials
\cite{eldred2008, maitre2010}
\[
  \Psi_\lc(G) = \hull{\left\{ \psi_{\vi}(\v{y}): \vi \in \sparseindex{n}{\lc}, \v{y} \in G \right\}}
\]
where $\vi = (i_k) \in \natural^n$, the index set $\sparseindex{n}{\lc}$ is the
one in \eref{index-total-order-isotropic}, and
\[
  \psi_{\vi}(\v{y}) = \prod_{k = 1}^n \psi_{i_k}(y_k).
\]
In the above formulae, $\psi_{i_k}: \real \to \real$ is a normalized
one-dimensional Hermite polynomial of order $i_k$. An important property of the
polynomials $\{ \psi_{\vi} \}$ is that they are mutually orthonormal with
respect to $F$, which means that
\begin{equation} \elab{chaos-orthogonality}
  \innerproduct{\psi_{\vi}}{\psi_{\vj}} = \delta_{\vi \vj}
\end{equation}
for any $\vi = (i_k) \in \natural^n$ and $\vj = (j_k) \in \natural^n$ where
\[
  \delta_{\vi \vj} = \prod_{k = 1}^n \delta_{i_k j_k},
\]
and $\delta_{i_k j_k}$ is the Kronecker delta. In addition, the polynomials are
centered with respect to $F$; therefore, the inner product in
\eref{chaos-inner-product} applied to two polynomials yields their correlation,
which is zero due to the orthogonality. Furthermore, the inner product applied
to a polynomial with itself yields the variance of that polynomial, which is
unity due to the normality.

Define
\begin{align*}
  & \Delta\Psi_{-1} = \emptyset \text{ and} \\
  & \Delta\Psi_i = \Psi_i(G) \, \cap \, \Psi_{i - 1}(G)^\perp.
\end{align*}
The vector spaces $\{ \Delta\Psi_i \}_{i = 0}^\infty$ are mutually orthogonal,
closed subspaces of $\L{2}{\Omega, \F, \probability}$. Since our scope of
interest is restricted to functions of \vx, \F is assumed to be generated by
\vx. Then, by the Cameron--Martin theorem,
\[
  \L{2}{\Omega, \F, \probability} = \bigoplus_{i = 0}^\infty \Delta\Psi_i.
\]
The decomposition is called the Wiener chaos decomposition; however, it is more
often referred to as the classical \ac{PC} decomposition.

The \ac{PC} decomposition implies that any $\f \in \L{2}{\Omega, \F,
\probability}$ admits the following infinite expansion with respect to the
polynomial basis:
\[
  \f = \sum_{\vi \in \natural^n} \hat{\f}_{\vi} \psi_{\vi}
\]
where the equality should be understood in mean square. The coefficients $\{
\hat{\f}_{\vi} \}$ of the expansion are found by taking the inner product with
respect to each $\psi_{\vi}$ from the basis on both sides of the above equation
and making use of the orthogonality property shown in
\eref{chaos-orthogonality}. The result is
\begin{equation} \elab{chaos-projection}
  \hat{\f}_{\vi} = \innerproduct{\\f}{\psi_{\vi}}
\end{equation}
This operation is referred to as a spectral projection.

In practice, the infinite expansion is to be truncated, which we denote by
\[
  \f \approx \chaos{n}{\lc}{\f} = \sum_{\vi \in \sparseindex{n}{\lc}} \hat{\f}_{\vi} \psi_{\vi}
\]
where $\sparseindex{n}{\lc}$ is a certain index set, frequently the one given in
\eref{index-total-order-isotropic}. In the notation $\chaos{n}{\lc}$, the
superscript $n$ indicates that there are $n$ random variables, and the subscript
\lc indicates the level of the truncated expansion.

The classical \ac{PC} decomposition can be generalized to other families of
probability distributions besides the Gaussian one. Many distributions directly
correspond to certain families of orthogonal polynomials, which can be found in
the Askey scheme of orthogonal polynomials. A distribution that does not have
such a correspondence can be transformed into one of those that do using
techniques such as the one shown in \xref{probability-transformation}. Another
solution is to construct a custom polynomial basis using the Gram--Schmidt
process. Note that the machinery of \ac{PC} expansions is applicable to discrete
probability distributions as well. The interested reader is referred to
\cite{xiu2010} for further discussions.
