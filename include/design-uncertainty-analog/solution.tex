The uncertainty imposed by process variation is addressed as follows. Due to the
inherent complexity, uncertainty-quantification problems are often viewed as
approximation problems: one constructs a computationally efficient surrogate for
the system under consideration and then studies this light representation
instead of the original system. In this chapter, we reside to the machinery of
the \acf{PC} decomposition described in \sref{polynomial-chaos} for the
construction of such a lightweight surrogate for the quantity of interest. The
expansions that we construct constitute an attractive alternative to \ac{MC}
sampling since they possess much faster convergence properties and provide
succinct and intuitive representations of system responses to stochastic inputs.
Having obtained the surrogate, we utilize it for calculating the desired
statistics about the quantity of interest such as its \acf{CDF}, \acf{PDF}, and
probabilistic moments.

To elaborate, we develop a framework for the analysis of electronic systems
subject to the uncertainty due to process variation. The framework is flexible
in modeling diverse probability distributions, specified by the designer, of the
uncertain parameters---such as the effective channel length and gate oxide
thickness. Moreover, there are no assumptions on the probability distribution of
the quantity of interest---such as power and temperature profiles---as this
distribution is unlikely to be known \emph{a priori}. The proposed technique is
capable of capturing arbitrary joint effects of the uncertain parameters on the
system since the impact of these parameters is introduced into the framework as
a ``black box,'' which is also defined by the designer. In particular, it allows
for the power-temperature interplay to be taken into account with no effort.

Leveraging the proposed framework, we extend the deterministic transient and
dynamic steady-state analysis presented in \sref{transient-analysis} and
\sref{dynamic-steady-state-analysis}, respectively, by accounting for the
uncertainty due to process variation. Moreover, the framework allows us to
enrich the reliability analysis presented in \sref{reliability-analysis}, which
is based on the state-of-the-art reliability models, by taking into
consideration the effect of process variation on temperature.

We illustrate the proposed framework by considering two important process
parameters that are affected by process variation, namely, the effective channel
length and gate oxide thickness; note, however, that our approach can be applied
to other parameters as well. Furthermore, we utilize the framework in order to
construct a computationally efficient design-space exploration procedure
targeted at the minimization of the energy consumption under probabilistic
constraints on the temperature and lifetime of the system.

\subsection{Power Model}

As stated in \sref{chaos-problem}, the designer is supposed to decide on the
power model for the system, which we denote as follows:
\begin{equation} \elab{chaos-power-model}
  \vp(t) = f(t, \vq, \vu)
\end{equation}
where $f: \real \times \real^\np \times \real^\nu \to \real^\np$ is a function
that evaluates the power consumption $\vp \in \real^\np$ of the processing
elements at time $t$ given the heat dissipation $\vq \in \real^\np$ of the
processing elements and the parameters $\vu \in \real^\nu$.

\begin{remark}
It should be understood that \vp, \vq, and \vu are random vectors in general,
and that $f$ consumes $\vq(t, \omega)$ and $\vu(\omega)$ and yields $\vp(t,
\omega)$ for some particular outcome $\omega \in \Omega$. The function itself is
purely deterministic.
\end{remark}

The designer can choose any $f$. It can be, for instance, a closed-form formula
or a piece of code. The only assumption we make about $f$ is that it is smooth
in \vz and belongs to $\L{2}(\Omega, \mathcal{F}, \probability)$ when it is
viewed as a random variable (see \sref{probability-theory}), which is generally
applicable to most physical systems \cite{xiu2010}. Note also that the operation
performed by this ``black box'' is purely deterministic. The definition of $f$
is flexible enough to account for such effects as the interdependence between
power and temperature discussed in \sref{power-model}.

\subsection{Temperature Model}

The temperature model is based on the one described in \sref{temperature-model},
and transient temperature analysis is based on the one presented in
\sref{transient-state-solution}. The major difference is that
\eref{temperature-model} implicitly operates on stochastic quantities.
Consequently, the recurrent solution in \eref{transient-state-recurrence}, that
is,
\begin{equation} \elab{chaos-recurrence-original}
  \vs_i = \m{E} \vs_{i - 1} + \m{F} \vp_i
\end{equation}
for $i = \range{1}{\ns}$ where $\vs_0 = \v{0}$, is such as well. In the
deterministic case, it can be readily employed to perform deterministic
transient power and temperature analysis via the techniques in
\sref{power-temperature-interplay}. In the stochastic case, however, the
situation is substantially different since $\vp_i$ and, consequently, $\vs_i$
and $\vq_i$ are probabilistic quantities. Moreover, at each step, $\vp_i$ is an
arbitrary transformation of the uncertain parameters \vu and stochastic
temperature $\vq_i$, which results in a multivariate random variable with a
generally unknown probability distribution. Furthermore, $\vp_i$, $\vq_i$,
$\vs_i$, and \vu are dependent random vectors since the first three are
functions of the last. Consequently, the operations involved in the recurrence
are to be performed on dependent random vectors with arbitrary probability
distributions, which, in general, have no closed-form solutions, which we
address in the following subsection.
