A bird's eye view of the remaining chapters of the thesis is as follows.

In \cref{background}, we introduce a number of commonly used models that
constitute a starting point for the developments presented in this thesis.
Specifically, these models are a general system model, a temperature-aware power
model, a temperature model, and a temperature-aware reliability model.

In \cref{certainty-development}, we consider techniques for deterministic
system-level analysis of computer systems. These techniques do not take
uncertainty into account; however, they serve as a solid foundation for those
that do. Our attention revolves primarily around power and temperature since
they are of central importance for attaining robustness and energy efficiency.
We develop a novel approach to dynamic steady-state temperature analysis of
computer systems and apply it in the context of temperature-aware reliability
optimization. Reliability optimization addresses performance uncertainty by
definition; however, the above-mentioned one falls in the scope of this chapter
since the accompanying reliability analysis treats temperature as a
deterministic quantity, which is suboptimal as we discuss and tackle in the
subsequent chapters.

In \cref{uncertainty-analog-fabrication}, we present our first technique
targeted at uncertainty. We develop a statistical approach to analyzing
process-variation-induced fluctuations of process parameters---such as the
effective channel length and gate oxide thickness---across silicon wafers by
means of indirect, incomplete, and noisy measurements such as readings from
thermal sensors. To this end, we make use of a suite of tools borrowed from the
field of Bayesian statistics.

In \cref{uncertainty-analog-development}, we continue working with process
uncertainty and present a technique that is applicable to studying diverse
quantities with respect to process variation. To this end, we leverage the
theory of polynomial chaos expansions. In particular, the proposed approach
allows for progressively analyzing transient power and temperature profiles of
computer systems. Other examples are the dynamic steady-state profile and such
critical metrics as the maximal temperature and energy consumption. They all can
be analyzed from the probabilistic standpoint, and the utility of this virtue is
illustrated by addressing a problem of design-space exploration with a set of
probabilistic constraints related to reliability. Unlike the reliability model
utilized in \cref{certainty-development}, the one presented in
\cref{uncertainty-analog-development} is well aware of process uncertainty and,
therefore, allows for a more adequate treatment of performance uncertainty.

In \cref{uncertainty-digital-development}, we develop another system-level
technique targeted at uncertainty. The tool makes use of adaptive hierarchical
interpolation on sparse grids and specializes in tackling digital sources of
uncertainty such as workload, which are typically less regular than the analog
ones including process variation. The proposed technique is exemplified by
quantifying the effect that workload units with unknown processing times have on
the timing-, power-, and temperature-related characteristics of the system under
consideration.

In \cref{uncertainty-digital-management}, we elaborate on runtime management of
computer systems under workload variation. In this context, we perform an early
investigation of the utility of advanced prediction techniques from machine
learning for fine-grained long-range forecasting of the resource usage in large
computer systems. Specifically, we study the applicability of recurrent neural
networks.

In \cref{conclusion}, we conclude the thesis by recapitulating our contribution.

The thesis also contains an appendix where we give an overview of a number of
concepts from such interconnected disciplines as linear algebra, probability
theory, statistics, numerical integration, and interpolation. The theory given
in the appendix is extensively utilized throughout the thesis.
