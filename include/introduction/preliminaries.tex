Before we proceed any further, let us first cover a few concepts and notations
that are extensively utilized throughout the thesis.

\subsection{Linear Algebra}
\slab{linear-algebra}

Vectors are denoted by bold lowercase. An $n$-dimensional vector $\v{x}$ in a
vector space such as $\real^n$ can be defined in a number of equivalent ways,
depending on what is important to emphasize in a particular context, as follows:
\begin{align*}
  & \v{x} = (x_i), \\
  & \v{x} = (x_i)_{i = 1}^n, \text{ and} \\
  & \v{x} = (\range{x_1}{x_n}).
\end{align*}
Matrices are denoted by bold uppercase letters. An $n_1 \times n_2$ matrix in a
vector space such as $\real^{n_1 \times n_2}$ can also be defined in several
ways as follows:
\begin{align*}
  & \m{X} = (x_{ij}), \\
  & \m{X} = (x_{ij})_{i = 1, j = 1}^{n_1, n_2}, \text{ and} \\
  & \m{X} = \left(
    \begin{array}{lll}
      x_{1 1}   & \cdots & x_{1 n_2}   \\
      \cdots    & \cdots & \cdots      \\
      x_{n_1 1} & \cdots & x_{n_1 n_2}
    \end{array}
  \right).
\end{align*}

Any symmetric matrix $\m{X} \in \real^{n \times n}$ admits the
eigendecomposition \cite{press2007}, which, in this particular case, takes the
following form:
\begin{equation} \elab{eigendecomposition}
  \m{X} = \m{U} \m{\Lambda} \transpose{\m{U}}
\end{equation}
where $\m{U} \in \real^{n \times n}$ is an orthogonal matrix of the eigenvectors
of $\m{X}$, and
\[
  \m{\Lambda} = \diagonal{\lambda_1}{\lambda_n} = \left(
    \begin{array}{lll}
      \lambda_1 & \cdots & 0         \\
      \cdots    & \cdots & \cdots    \\
      0         & \cdots & \lambda_n
    \end{array}
  \right) \in \real^{n \times n}
\]
is a diagonal matrix of the eigenvalues of $\m{X}$.

\subsection{Probability Theory}
\slab{probability-theory}

Let $(\Omega, \mathcal{F}, \probability)$ be a probability space where $\Omega$
is a set of outcomes, $\mathcal{F} \subseteq 2^\Omega$ is a $\sigma$-algebra on
$\Omega$, and $\probability: \mathcal{F} \to [0, 1]$ is a probability measure
\cite{durrett2010}. The $\sigma$-algebra represents a set of events, and the
probability measure assigns probabilities to these events. A (real-valued)
random variable defined on $(\Omega, \mathcal{F}, \probability)$ is an
$\mathcal{F}$-measurable function $x: \Omega \to \real$. A random variable $x$
is uniquely characterized by its distribution function $F$, also known as the
\ac{CDF}, defined by
\begin{equation*}
  F(x^*) = \probability{x \leq x^*} = \probability{\{ \omega \in \Omega: x(\omega) \leq x^* \}}.
\end{equation*}
The expectation of $x$ is given by
\[
  \expectation{x} = \int_\real x^* dF(x^*) = \int_\Omega x(\omega) dP(\omega),
\]
The covariance of two random variable $x_1$ and $x_2$ is given by
\[
  \covariance{x_1}{x_2} = \expectation{((x_1 - \expectation{x_1})(x_2 - \expectation{x_2}))}.
\]
The variance of $x$ is given by
\[
  \variance{x} = \covariance{x}{x} = \expectation{(x - \expectation{x})^2}.
\]

The above quantities are well defined only when the corresponding integrals are
finite. An example of a space of random variables defined on $(\Omega,
\mathcal{F}, \probability)$ whose expectations and variances are finite is
$\L{2}(\Omega, \mathcal{F}, \probability)$, the Hilbert space of
square-integrable random variables \cite{janson1997} with the inner product
defined by
\[
  \innerproduct{x_1}{x_2}_\L{2} = \expectation{(x_1 x_2)}
\]
and the norm defined by
\[
  \norm[\L{2}]{x} = \sqrt{\innerproduct{x}{x}_\L{2}}
\]
for any $x$, $x_1$, and $x_2$ in $\L{2}(\Omega, \mathcal{F}, \probability)$.

If the distribution function $F$ of a random variable $x$ is continuous, $x$ is
said to be a continuous random variable. If, moreover, $F$ is absolutely
continuous, $x$ has a \ac{PDF} $f$ defined by
\[
  f(x) = \frac{dF(x)}{dx}.
\]
Other types of random variables such as discrete random variables are of little
interest to this thesis, and, therefore, they are not covered here.

An $n$-dimensional random variable or random vector $\v{x} = (x_i)_{i = 1}^n$ is
a collection of $n$ random variables or, equivalently, a single random variable
that happens to take values in $\real^n$, which is written as $\v{x}: \Omega \to
\real^n$. Analogously to the one-dimensional case, $\v{x}$ is governed by a
distribution function, which is $n$-variate, has an expectation and a variance
(if the corresponding integrals are finite), which are $n$-dimensional, and has
a \ac{PDF} (if the distribution function is absolutely continuous in each
variable), which is $n$-variate. In addition, the covariance matrix of $\v{x}$
is given by
\begin{equation} \elab{covariance-matrix}
  \covariance{\v{x}} = \left(\covariance{x_i}{x_j}\right)_{i = 1, j = 1}^{n, n},
\end{equation}
which is positive semi-definite by definition.

\subsection{Probability Transformation}
\slab{probability-transformation}

The eigendecomposition in \eref{eigendecomposition} applied to
\eref{covariance-matrix} provides a useful transformation, which is known as the
discrete \ac{KL} decomposition \cite{ghanem1991, xiu2010} and is closely related
to principal component analysis \cite{hastie2013}. The decomposition transforms
$n$ potentially correlated variables $\v{x}$ into $n$ linearly uncorrelated
variables \vz whose variances are given by the corresponding eigenvalues (they
are non-negative since the matrix is positive semi-definite). More concretely,
the relationship between the two vectors is as follows:
\[
  \v{x} = \m{U} \m{\Lambda}^\frac{1}{2} \vz.
\]
When $\v{x}$ obeys a multivariate Gaussian distribution, the individual
variables in \vz follow the standard Gaussian distribution and are independent.

In addition, the decomposition provides a means of model order reduction. In
this case, we are to select the smallest subset of the uncorrelated variables
such that its cumulative contribution to the total variance is above a certain
threshold. Formally, assuming that $\{ \lambda_i: i = \range{1}{n} \}$ are
sorted in the descending order and given a threshold $\eta \in (0, 1]$, which is
the fraction of the total variance to be preserved, we identify the smallest
$\nz \leq n$ such that
\[
  \frac{\sum_{i = 1}^\nz \lambda_i}{\sum_{i = 1}^n \lambda_i} \geq \eta.
\]
Then, given a vector \vz in the reduced space $\real^\nz$, the corresponding
vector $\v{x}$ in the original space $\real^n$ can be lossy reconstructed as
follows:
\begin{equation} \elab{model-order-reduction}
  \v{x} = \m{U} \tm{\Lambda}^\frac{1}{2} \vz.
\end{equation}
In the above formula, $\tm{\Lambda} \in \real^{n \times \nz}$ is a truncated
version of $\m{\Lambda} \in \real^{n \times n}$ given in
\eref{eigendecomposition}, that is, the matrix contains only the first \nz
columns of $\m{\Lambda}$.

\subsection{Numerical Integration}
\slab{numerical-integration}

In numerical analysis, the integral of a function $g$ over a domain $D \subseteq
\real$
\[
  \int_D g(x) dx
\]
is approximated by a summation of the function's values computed at prescribed
points $\{ \hat{x}_i \in D \}$ and multiplied by prescribed weights $\{ w_i \in
\real \}$
\[
  \quadrature{1}{\lq}{g} = \sum_{i = 1}^\nq g(\hat{x}_i) w_i
\]
where \nq is the number of pairs of a point and a weight. Such a set of points
and a set of weights are called a quadrature rule, which we denote by
$\quadrature{1}{\lq}$. The superscript indicates that it is a one-dimensional
problem, and the subscript indicates the accuracy level of the rule used, which,
in the one-dimensional case, corresponds to the maximum order of polynomials
that the rule integrates exactly \cite{heiss2008}. Similarly, the integral of a
function $g$ over a domain $D \subseteq \real^n$
\[
  \int_D g(\v{x}) d\v{x}
\]
is approximated by
\[
  \quadrature{n}{\lq}{g} = \sum_{i = 1}^\nq g(\hat{\v{x}}_i) w_i.
\]
In this multidimensional case, an appropriate $n$-dimensional quadrature rule
$\quadrature{n}{\lq}$ is formed by computing the tensor product of $n$
potentially distinct one-dimensional quadrature rules, and the accuracy level
\lq refers to the index of the rule in the corresponding family of
multidimensional rules with increasing accuracy. The number of terms in the
summation \nq is dictated by both $n$ and \lq. Lastly, let us note that
quadrature rules are generally precomputed and tabulated since they do not
depend the integrand; see, for instance, \cite{burkardt}.

Consider now the following more general integral:
\[
  \int_D g(\v{x}) dF(\v{x}).
\]
Here $g$ is integrated with respect to a measure \cite{durrett2010}, denoted by
$F$, that does not necessarily corresponds to the usual Lebesgue measure used in
the earlier examples. The integrand can often be rewritten as follows:
\[
  \int_D g(\v{x}) f(\v{x}) d\v{x}
\]
where $g$ is weighted by a function $f$ and integrated with respect to the
Lebesgue measure as before. Since integrating in such a way is a very frequent
operation as we shall see, there are families of quadrature rules that are
designed to automatically taken into account the most common scenarios.

There is one more and arguably the most crucial aspect of numerical integration
that we ought to discuss: the algorithm used to construct multidimensional
quadrature rules. In low dimensions, the construction can be based on the direct
tensor product of one-dimensional rules. However, in high dimensions, the
situation changes dramatically as the number of points produced by this approach
can easily explode. For instance \cite{heiss2008}, if a one-dimensional rule has
only 4 points, that is, $\nq = 4$, then in 10 stochastic dimensions, that is, $n
= 10$, the number of multivariate points becomes $\nq = 4^{10} > 10^6$, which is
not affordable. Moreover, it can be shown that most of the points obtained in
this way do not contribute to the asymptotic accuracy and, hence, are a waste of
time. In order to tackle this problem, one resides to sparse integration grids
constructed via the Smolyak algorithm \cite{burkardt, eldred2008, heiss2008}.
The algorithm preserves the accuracy of the underlying one-dimensional rules for
complete polynomials while significantly reducing the number of points. For
instance, in the example given earlier, the number of points computed by the
algorithm would be only around 1600, which implies a drastic saving of the
computation time.

\subsection{Polynomial Chaos}
\slab{polynomial-chaos}

Due to the inherent complexity, uncertainty-quantification problems are
typically viewed as approximation problems: one usually constructs a
computationally efficient surrogate for the system under consideration and then
studies this light representation instead of the original system. One way to
construct such a surrogate is \ac{PC} \cite{xiu2010}. The technique decomposes
stochastic quantities into infinite series of orthogonal polynomials of random
variables. Such series are especially attractive from the post-processing
perspective as they are nothing more than polynomials; therefore, \ac{PC}
expansions are easy to interpret and easy to evaluate.

Let $\{ \psi_i: \real^n \to \real \}$ be a basis composed of $n$-variate
polynomials. The inner product in the Hilbert space spanned by the polynomials
is defined as the following $n$-dimensional integral:
\begin{equation} \elab{inner-product}
  \innerproduct{\psi_i}{\psi_j} = \int_{\real^n} \psi_i(\vz) \psi_j(\vz) f(\vz) d\vz.
\end{equation}
where $f: \real^n \to \real$ is a weight function, which we shall discuss
shortly. Two polynomials $\psi_i$ and $\psi_j$ are orthogonal if
\begin{equation} \elab{polynomial-orthogonality}
  \innerproduct{\psi_i}{\psi_j} = \innerproduct{\psi_i}{\psi_i} \delta_{ij}
\end{equation}
where $\delta_{ij}$ is the Kronecker delta function. A polynomial basis is
called orthogonal if any two polynomials from the basis are orthogonal.

In the case of \ac{PC}, the weight function is a \ac{PDF}. Assuming that the
corresponding distribution is centered, that is, it has a zero mean, the inner
product corresponds to the covariance operator; and orthogonality corresponds to
the absence of correlations.

Many of the most popular probability distributions directly correspond to
certain families of the orthogonal polynomials given in the Askey scheme
\cite{xiu2010}. A probability distribution that does not have such a
correspondence can be transformed into one of those that do have using the
technique shown in \sref{ie-uncertain-parameters}. Another solutions is to
construct a custom polynomial basis using the Gram-Schmidt process. In addition,
apart from continuous, PC expansions can be applied to discrete distributions.
Refer to \cite{xiu2010} for further discussions.

In multiple dimensions, which is the case with the \nz-dimensional random vector
\vz, several (possibly different) univariate bases are combined together in
order to produce a single \nz-variate basis, which we denote by $\{ \psi_j:
\real^\nz \to \real \}_{j = 1}^\infty$; see \cite{xiu2010}.

\subsection{Bayesian Statistics}
\slab{bayesian-statistics}

Let \u be a set of unknown parameters that we would like to know. In order to
find them, the following information is at our disposal: \one~a set of
observations $H$ of a quantity \h that is related to \u; \two~a data model that
describes the relation between \u and \h; and \three~prior beliefs about what \u
should be. A natural solution is Bayes' theorem \cite{gelman2004}, which is as
follows:
\begin{equation} \elab{bayes-theorem}
  p(\u | H) \propto p(H | \u) p(\u)
\end{equation}
where $p$ denotes a probability density function. In \eref{bayes-theorem}, $p(H
| \u)$ is known as the likelihood function, which accommodates the data model
and yields the probability of observing the data set $H$ given the parameters
\u; $p(\u)$ is called the prior of \u, which represents our knowledge on \u
prior to any observations; and $p(\u | H)$ is known as the posterior of \u given
$H$. The last is an exhaustive solution to our problem: having constructed $p(\u
| H)$, all the needed information about \u can be trivially estimated by drawing
samples from this posterior.

The posterior distribution does not typically belong to any of the common
families of probability distributions, which is primarily due to the data model
involved in the likelihood function, and, therefore, the sampling procedure is
not straightforward. In order to tackle the difficulty, one usually relies on
Markov chain Monte Carlo sampling \cite{gelman2004}. In this case, an ergodic
Markov chain with the stationary distribution equal to the target posterior
distribution is constructed and then utilized for exploring the probability
space. A popular technique in this regard is the Metropolis--Hastings algorithm
where the chain is constructed via sampling from a computationally convenient
distribution known as the proposal distribution. Each sample drawn from the
proposal is passed through the posterior in order to calculates its posterior
probability, which is then used to decide whether the sample should be accepted
or rejected. A rejection means that the sequence of samples advances using the
last accepted sample as if it was drawn once again. The acceptance strategy of
the algorithm pushes the produced chain of samples toward regions of high
posterior probability, which, after a sufficient number of steps, depending on
the starting point of the chain and the efficiency of the moves, results in an
adequate approximation of the target posterior distribution.
