Before we proceed any further, let us first cover a few concepts and notations
that are extensively utilized throughout the thesis.

\subsection{Linear Algebra}
\slab{linear-algebra}

Vectors are denoted by bold lowercase. An $n$-dimensional vector $\v{a}$ in a
vector space such as $\real^n$ can be defined in a number of equivalent ways,
depending on what is important to emphasize in a particular context, as follows:
\begin{align*}
  & \v{a} = (a_i), \\
  & \v{a} = (a_i)_{i = 1}^n, \text{ and} \\
  & \v{a} = (\range{a_1}{a_n}).
\end{align*}
Matrices are denoted by bold uppercase letters. An $n_1 \times n_2$ matrix in a
vector space such as $\real^{n_1 \times n_2}$ can also be defined in several
ways as follows:
\begin{align*}
  & \m{A} = (a_{ij}), \\
  & \m{A} = (a_{ij})_{i = 1, j = 1}^{n_1, n_2}, \text{ and} \\
  & \m{A} = \left(
    \begin{array}{lll}
      a_{1 1}   & \cdots & a_{1 n_2}   \\
      \cdots    & \cdots & \cdots      \\
      a_{n_1 1} & \cdots & a_{n_1 n_2}
    \end{array}
  \right).
\end{align*}

Any symmetric matrix $\m{A} \in \real^{n \times n}$ admits the
eigendecomposition \cite{press2007}, which, in this particular case, takes the
following form:
\begin{equation} \elab{eigendecomposition}
  \m{A} = \m{U} \m{\Lambda} \transpose{\m{U}}
\end{equation}
where $\m{U} \in \real^{n \times n}$ is an orthogonal matrix of the eigenvectors
of $\m{A}$, and
\[
  \m{\Lambda} = \diagonal{\lambda_1}{\lambda_n} = \left(
    \begin{array}{lll}
      \lambda_1 & \cdots & 0         \\
      \cdots    & \cdots & \cdots    \\
      0         & \cdots & \lambda_n
    \end{array}
  \right) \in \real^{n \times n}
\]
is a diagonal matrix of the eigenvalues of $\m{A}$.

\subsection{Probability Theory}
\slab{probability-theory}

Let $(\Omega, \mathcal{F}, \probability)$ be a probability space where $\Omega$
is a set of outcomes, $\mathcal{F} \subseteq 2^\Omega$ is a $\sigma$-algebra on
$\Omega$, and $\probability: \mathcal{F} \to [0, 1]$ is a probability measure
\cite{durrett2010}. The $\sigma$-algebra represents a set of events, and the
probability measure assigns probabilities to these events. A (real-valued)
random variable defined on $(\Omega, \mathcal{F}, \probability)$ is an
$\mathcal{F}$-measurable function $x: \Omega \to \real$. A random variable $x$
is uniquely characterized by its distribution function, also known as the
\ac{CDF}, defined by
\begin{equation*}
  F_x(x^*) = \probability{x \leq x^*} = \probability{\{ \omega \in \Omega: x(\omega) \leq x^* \}}.
\end{equation*}
The expectation of $x$ is given by
\[
  \expectation{x} = \int_\real x^* dF_z(x^*) = \int_\Omega x(\omega) dP(\omega),
\]
The covariance of $x$ and a random variable $y$ is given by
\[
  \covariance{x}{y} = \expectation{((x - \expectation{x})(y - \expectation{y}))}.
\]
The variance of $x$ is given by
\[
  \variance{x} = \covariance{x}{x} = \expectation{(x - \expectation{x})^2}.
\]
The above quantities are well defined only when the corresponding integrals are
finite. An example of a space of random variables defined on $(\Omega,
\mathcal{F}, \probability)$ whose expectations and variances are finite is
$\L{2}(\Omega, \mathcal{F}, \probability)$, the Hilbert space of
square-integrable random variables \cite{janson1997} with the inner product
defined by
\[
  \innerproduct{x}{y}_\L{2} = \expectation{(x y)}
\]
and the norm defined by
\[
  \norm[\L{2}]{x} = \innerproduct{x}{x}^\frac{1}{2}
\]
for any random variables $x$ and $y$ in $\L{2}(\Omega, \mathcal{F},
\probability)$.

An $n$-dimensional random variable or random vector $\v{x} = (x_i)_{i = 1}^n$ is
a collection of $n$ random variables or, equivalently, a single random variable
that happens to take values in $\real^n$, which is written as $\v{x}: \Omega \to
\real^n$. Analogous to the one-dimensional case, $\v{x}$ obeys a certain (joint)
distribution function and has an expectation and a variance (if they are
finite), which are $n$-dimensional in this case. In addition, the covariance
matrix of $\v{x}$ is defined as follows:
\begin{equation} \elab{covariance-matrix}
  \covariance{\v{x}} = \left(\covariance{x_i}{x_j}\right)_{i = 1, j = 1}^{n, n},
\end{equation}
which is positive semi-definite by definition.

The eigendecomposition in \eref{eigendecomposition} applied to
\eref{covariance-matrix} provides a useful transformation, which is known as the
discrete \ac{KL} decomposition \cite{ghanem1991, xiu2010} and is closely related
to principal component analysis \cite{hastie2013}. The decomposition transforms
$n$ potentially correlated variables $\v{x}$ into $n$ linearly uncorrelated
variables $\v{z}$ whose variances are given by the corresponding eigenvalues
(they are non-negative since the matrix is positive semi-definite). More
concretely, the relationship between the two vectors is as follows:
\[
  \v{x} = \m{U} \m{\Lambda}^\frac{1}{2} \vz.
\]
In addition, the decomposition provides a means of model order reduction. In
this case, we are to select the smallest subset of the uncorrelated variables
such that its cumulative contribution to the total variance is above a certain
threshold. Formally, assuming that $\{ \lambda_i: i = \range{1}{n} \}$ are
sorted in the descending order and given a threshold $\eta \in (0, 1]$, which is
the fraction of the total variance to be preserved, we identify the smallest
$\nz \leq n$ such that
\[
  \frac{\sum_{i = 1}^\nz \lambda_i}{\sum_{i = 1}^n \lambda_i} \geq \eta.
\]
Then, given a vector \vz in the reduced space $\real^\nz$, the corresponding
vector $\v{x}$ in the original space $\real^n$ can be lossy reconstructed as
follows:
\begin{equation} \elab{model-order-reduction}
  \v{x} = \m{U} \tm{\Lambda}^\frac{1}{2} \vz.
\end{equation}
In the above formula, $\tm{\Lambda} \in \real^{n \times \nz}$ is a truncated
version of $\m{\Lambda} \in \real^{n \times n}$ given in
\eref{eigendecomposition}, that is, the matrix contains only the first \nz
columns of $\m{\Lambda}$.

\subsection{Bayesian Statistics}
\slab{bayesian-statistics}

Let \u be a set of unknown parameters that we would like to know. In order to
find them, the following information is at our disposal: \one~a set of
observations $H$ of a quantity \h that is related to \u; \two~a data model that
describes the relation between \u and \h; and \three~prior beliefs about what \u
should be. A natural solution is Bayes' theorem \cite{gelman2004}, which is as
follows:
\begin{equation} \elab{bayes-theorem}
  p(\u | H) \propto p(H | \u) p(\u)
\end{equation}
where $p$ denotes a probability density function. In \eref{bayes-theorem}, $p(H
| \u)$ is known as the likelihood function, which accommodates the data model
and yields the probability of observing the data set $H$ given the parameters
\u; $p(\u)$ is called the prior of \u, which represents our knowledge on \u
prior to any observations; and $p(\u | H)$ is known as the posterior of \u given
$H$. The last is an exhaustive solution to our problem: having constructed $p(\u
| H)$, all the needed information about \u can be trivially estimated by drawing
samples from this posterior.

The posterior distribution does not typically belong to any of the common
families of probability distributions, which is primarily due to the data model
involved in the likelihood function, and, therefore, the sampling procedure is
not straightforward. In order to tackle the difficulty, one usually relies on
Markov chain Monte Carlo sampling \cite{gelman2004}. In this case, an ergodic
Markov chain with the stationary distribution equal to the target posterior
distribution is constructed and then utilized for exploring the probability
space. A popular technique in this regard is the Metropolis--Hastings algorithm
where the chain is constructed via sampling from a computationally convenient
distribution known as the proposal distribution. Each sample drawn from the
proposal is passed through the posterior in order to calculates its posterior
probability, which is then used to decide whether the sample should be accepted
or rejected. A rejection means that the sequence of samples advances using the
last accepted sample as if it was drawn once again. The acceptance strategy of
the algorithm pushes the produced chain of samples toward regions of high
posterior probability, which, after a sufficient number of steps, depending on
the starting point of the chain and the efficiency of the moves, results in an
adequate approximation of the target posterior distribution.
