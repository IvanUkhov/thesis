Analogous to the optimization given in \sref{dream-optimization}, the framework
proposed in this chapter is illustrated in the context of design-space
exploration. Concretely, we pursue energy minimization in the presence of
process variation.

\subsection{\problemtitle}

The general setup is the same as the one described in
\sref{dream-optimization-problem}. We continue working with the thermal-cycling
fatigue \cite{jedec2016}, which is introduced in \sref{thermal-cycling-fatigue}
and motivated in \sref{dream-optimization}. Recall that the system is exposed a
periodic or approximately periodic workload, and that the corresponding
temperature profile is a dynamic steady-state temperature profile. In the
deterministic case, this profile can be computed as described in
\sref{dynamic-steady-solution}.

The goal of the optimization in this section is to find a schedule that
minimizes the energy consumption of the system while satisfying certain
constraints. Specifically, our objective is as follows:
\begin{equation} \elab{chaos-optimization-objective}
  \min_{\schedule} \expectation{(E(\schedule))}
\end{equation}
such that
\begin{equation} \elab{chaos-optimization-constraints}
  \begin{split}
    & \period(\schedule) \leq \period_\maximum, \\
    & \probability{Q(\schedule) \geq \q_\maximum} \leq \rho_\burn, \text{ and} \\
    & \probability{\expectation{\left(\life(\schedule)\right)} \leq \life_\minimum} \leq \rho_\wear
  \end{split}
\end{equation}
where
\begin{align*}
  & E(\schedule) = \dt \, \norm[1]{\mp(\schedule)} \text{ and} \\
  & Q(\schedule) = \norm[\infty]{\mq(\schedule)}.
\end{align*}
To begin with, \schedule denotes a schedule (recall that a schedule includes not
only the starting times of the tasks but also their mapping onto the processing
elements); \mp and \mq are the corresponding dynamic steady-state power and
temperature profiles, respectively; \dt is their sampling interval; and
$\norm[1]{\cdot}$ and $\norm[\infty]{\cdot}$ are the Manhattan and uniform
norms, respectively. The objective in \eref{chaos-optimization-objective} is to
minimize the expectation of the total energy consumption $E: \Omega \to \real$,
which is a random variable since energy depends on power, and power depends on
the uncertain parameters \vu. The constraints in
\eref{chaos-optimization-constraints} concern time, temperature, and
reliability. The first one constrains the end-to-end delay \period of the
application by a deadline $\period_\maximum$. The second one constrains the
maximum temperature $Q: \Omega \to \real$ of the platform by $\q_\maximum$ where
$\rho_\burn$ is an acceptable probability of burning the chip. The third one
constrains (from below) the lifetime $\life: \Omega \to \real$ of the system by
$\life_\minimum$ where $\rho_\wear$ is an acceptable probability of having a
premature fault due to wear.

The first constraint in \eref{chaos-optimization-constraints} is deterministic.
On the other hand, the other two constraints are probabilistic since they are
based on stochastic quantities. In the very last constraint, we set an upper
bound on the expectation of \life. It should be noted that this expectation is a
random variable \perse due to the nested structure of the reliability model
discussed in \rref{chaos-nested-uncertainty}.

In this section, the quantity of interest \g in \fref{chaos-overview} is the
vector
\begin{equation} \elab{chaos-optimization-quantity}
  \vg = (E, Q, \life)
\end{equation}
where the first element corresponds to the total energy consumption; the second
one is the maximum temperature; and, with a slight abuse of notation, the third
one is the parameters of the reliability model characterizing the lifetime,
which are denoted by \vg in \sref{reliability-model} and
\sref{chaos-reliability-analysis}. Each element implicitly depends on \schedule
and \vu. In \aref{chaos-construction}, Algorithm~G is a subroutine that
transforms \vz into \vu, makes a call to
\aref{chaos-dynamic-steady-solution-iterative}, and processes the resulting
power and temperature profiles as required in order to compute the above \vg.

The construction of a surrogate at Stage~3 is standard; see
\sref{chaos-construction}. On the other hand, the post-processing stage,
Stage~4, is worth discussing.

\subsection{Post-Processing}

In this context, the post-processing stage concerns the usage of expansions of
\eref{chaos-optimization-quantity} inside an optimization procedure whose
objective and constraints are the ones shown in
\eref{chaos-optimization-objective} and \eref{chaos-optimization-constraints},
respectively.

We begin by delineating the optimization procedure itself. Similar to
\sref{dream-optimization}, we make use of a genetic algorithm
\cite{schmitz2004}. Each chromosome contains $2 \nt$ genes that encode a mapping
of the tasks onto the processing elements and a vector of priorities of the
tasks; the two pieces of information are needed for scheduling as explained
below. The population contains $4 \nt$ individuals that are initialized using
uniform distributions. The parents for the next generation are chosen by a
tournament selection with the number of competitors equal to 20\% of \nt. A
one-point crossover is then applied to 80\% of the parents. Each parent
undergoes a uniform mutation where each gene is altered with probability 0.01.
The top five-percent individuals always survive. The stopping condition is the
absence of improvement within 10 successive generations.

Let us now turn to the evaluation of the fitness of a chromosome, which is where
\ac{PC} expansions come into play. First, the information encoded in the
chromosome is fed into a list scheduler \cite{adam1974}, and the scheduler
produces a schedule \schedule. We then check the timing constraint (the first
one in \eref{chaos-optimization-constraints}), which does not require any
uncertainty analysis. If it is violated, we set the fitness to the amount of
this violation relative to the constraint---that is, to the difference between
the actual end-to-end delay and the deadline $\period_\maximum$ divided by
$\period_\maximum$---and add a big constant $C$. If the timing constraint is
satisfied, we perform our uncertainty analysis and proceed to checking the
temperature and lifetime constraints. If any of them is violated, we set the
fitness to the total relative amount of violation plus $C / 2$. If all the
constraints are satisfied, the fitness of the chromosome is set to the expected
energy consumption.

The aforementioned examination of the temperature and lifetime constraints as
well as the evaluation of the expected energy consumption are undertaken by
means of a \ac{PC} expansion of \eref{chaos-optimization-quantity} using the
description given in \sref{chaos-processing}. Specifically, the two
probabilities needed in \eref{chaos-optimization-constraints} are estimated via
sampling the light polynomial surrogate. By contrast, the expectation in
\eref{chaos-optimization-objective} requires no sampling and is
straightforwardly computed using the analytical formula shown in
\eref{chaos-moments}.

\begin{remark}
In order to speed up the optimization, we use caching and parallel computing.
Concretely, the fitness value of each evaluated chromosome is stored in memory
and reused whenever a chromosome with the same set of genes is encountered, and
unseen (not cached) individuals are assessed in parallel.
\end{remark}
