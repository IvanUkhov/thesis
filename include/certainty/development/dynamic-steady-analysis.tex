Dynamic steady-state analysis addresses the shortcomings of static steady-state
analysis in one particular but important context. It tackles the scenario where
power consumption follows a periodic pattern. In this case, after a sufficiently
long time, the system does not reach a static steady state but instead a dynamic
steady state where temperature starts to exhibit a periodic pattern following
the periodic pattern of power. The goal of the analysis is then to find the
periodic temperature profile \mq, called the dynamic steady-state temperature
profile, that corresponds to a given periodic power profile \mp.

In the case of applications that exhibit periodic or close to periodic
behaviors, this analysis is of particular importance. Any design optimization
has to be performed such that the efficiency and reliability of the system at
hand are maximized by considering not a relatively short transient time interval
at the system's start but the context in which the system is to function over a
long period of time, which is exactly the dynamic steady state of the system.

A prominent example of a design task for which the analysis is of central
importance is reliability optimization targeted at mitigating thermal-cycling
fatigue \cite{jedec2016}. As noted in \sref{thermal-cycling-fatigue}, in this
context, the lifetime of the system is impacted not only by the average and
maximum temperature but also by the amplitude and frequency of temperature
oscillations. Thus, efficient reliability optimization depends on the
availability of the actual dynamic steady-state temperature profile, which we
discuss further in \sref{dream-optimization}.

\subsection{\pasttitle}
\slab{dynamic-steady-past}

Let us elaborate on the two techniques that have been presented in the
literature in order to calculate the dynamic steady-state temperature profile.

The first technique is referred to as the iterative transient approximation. In
this case, an estimate of the profile is calculated by running a temperature
simulator over a number of successive periods of the application until a
sufficiently accurate approximation of the dynamic steady state is assumed to be
attained \cite{srinivasan2004}. The typical simulator of choice in this context
is HotSpot \cite{skadron2003}, which is the state of the art in system-level
temperature analysis of electronic systems; see, for instance,
\cite{srinivasan2004, liao2005, coskun2006, liu2007, huang2009b, xiang2010,
thiele2011, oboril2012, pagani2014}. The simulator performs transient
temperature analysis by solving the system in \eref{temperature-model-original}
numerically by means of the fourth-order Runge--Kutta method \cite{press2007}.

\inputfigure{dream-iterative-transient-accuracy}
The number of iterations required to reach the dynamic steady state depends on
the thermal characteristics of the platform. In order to illustrate this aspect,
consider an application with a period of 500~ms running on five hypothetical
platforms with processing-element areas of 1--25~\power{mm}{2}. Let us simulate
50 successive periods of the application via HotSpot with its default settings
and compare the resulting approximations in each period with the actual dynamic
steady-state temperature profiles---whose calculation is to be discussed in
\sref{dynamic-steady-solution}---using the \ac{NRMSE}. The comparison is shown
in \fref{dream-iterative-transient-accuracy}. It can be observed that the number
of successive periods over which transient analysis has to be performed in order
to achieve a satisfactory level of accuracy is significant for the majority of
the configurations, which entails large computation times. For instance, for an
area of 9~\power{mm}{2}, even after 15 iterations, the \ac{NRMSE} is still close
to 20\%. Using the analytical approach to transient analysis presented in
\sref{transient-analysis}, the iterative transient approximation can be sped up;
however, the large number of iterations still makes the computational cost
unreasonably high, as discussed further in \sref{dynamic-steady-results}.
Moreover, the approach provides no guarantees on the resulting accuracy, since
there is no reliable metric for measuring the proximity to the actual solution,
the actual dynamic steady-state temperature profile.

The second technique is referred to as the static steady-state approximation. It
is a crude but fast technique proposed in \cite{huang2009b}. The approach
forgoes transient analysis and resorts to static steady-state analysis instead.
Specifically, it is assumed that, in each time interval where the system's power
consumption is constant, the system instantaneously reaches a static steady
state. The result of this procedure is a stepwise temperature curve where each
step corresponds to the static steady-state temperature that would be reached if
the corresponding power was applied for a sufficiently long period of time.

\inputfigure{dream-static-steady-example}
\inputfigure{dream-static-steady-accuracy}
An example of such an approximation, along with the actual dynamic steady-state
temperature profile, for an application with 10 tasks and a period of 100~ms is
given in \fref{dream-static-steady-example}. The processing-element area is
25~\power{mm}{2} in this case. The reduced accuracy of this technique is due to
the mismatch between the actual temperature within each interval and the static
steady-state temperature. The inaccuracy depends on the thermal characteristics
of the platform and on the application itself. In order to illustrate this, let
us simulate five applications with periods of 10--1000~ms running on five
platforms with an area per processing element of 1--25~\power{mm}{2}. The errors
are shown in \fref{dream-static-steady-accuracy}. It can be seen that, for
example, for an area of 10~\power{mm}{2} and a period of 100~ms, the \ac{NRMSE}
of this approximation technique is close to 40\%.

To conclude, the current state-of-the-art techniques for dynamic steady-state
temperature analysis are slow and inaccurate. This state of affairs makes them
difficult and dangerous from the standpoint of design optimization.

\subsection{\solutiontitle}
\slab{dynamic-steady-solution}

In this subsection, we formalize the problem of dynamic steady-state temperature
analysis and develop an exact and, moreover, computationally efficient solution
to this problem, which eliminates the shortcomings of the state-of-the-art
solutions discussed in the previous subsection.

Consider the temperature model in \eref{temperature-model} and the corresponding
recurrence in \eref{transient-recurrence}. The key condition of a dynamic steady
state is
\begin{equation} \elab{dynamic-steady-condition}
  \vs_0 = \vs_\ns.
\end{equation}
The above condition means that, once the dynamic steady state has been reached,
the electronic system starts returning to its initial state at the end of each
iteration, which is what makes the system's behavior periodic. Then, using
\eref{transient-recurrence}, the dynamic steady-state temperature profile can be
computed by solving the following system of linear equations:
\[
  \begin{cases}
    \vs_1 - \m{E} \vs_\ns & = \m{F} \vp_1 \\
    \dots \\
    \vs_\ns - \m{E} \vs_{\ns - 1} & = \m{F} \vp_\ns
  \end{cases}
\]
where the first equation enforces the boundary condition in
\eref{dynamic-steady-condition}. In order to get the big picture, the system can
be rewritten as follows:
\begin{equation} \elab{dynamic-steady-system}
  \resizebox{0.89\linewidth}{!}{
    $\underbrace{\left[
      \begin{array}{rrrrrrr}
        \m{I}  & \v{0}  & \v{0}  & \cdots & \v{0}  & \v{0}  & -\m{E} \\
        -\m{E} & \m{I}  & \v{0}  & \cdots & \v{0}  & \v{0}  & \v{0}  \\
        \v{0}  & -\m{E} & \m{I}  & \cdots & \v{0}  & \v{0}  & \v{0}  \\
        \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots \\
        \v{0}  & \v{0}  & \v{0}  & \cdots & \m{I}  & \v{0}  & \v{0}  \\
        \v{0}  & \v{0}  & \v{0}  & \cdots & -\m{E} & \m{I}  & \v{0}  \\
        \v{0}  & \v{0}  & \v{0}  & \cdots & \v{0}  & -\m{E} & \m{I}
      \end{array}
    \right]}_{\displaystyle \mathbb{A}} \underbrace{\left[
      \begin{array}{l}
        \vs_1         \\
        \vs_2         \\
        \vs_3         \\
        \cdots        \\
        \vs_{\ns - 2} \\
        \vs_{\ns - 1} \\
        \vs_\ns
      \end{array}
    \right]}_{\displaystyle \mathbb{X}} = \underbrace{\left[
      \begin{array}{l}
        \m{F} \vp_1         \\
        \m{F} \vp_2         \\
        \m{F} \vp_3         \\
        \cdots              \\
        \m{F} \vp_{\ns - 2} \\
        \m{F} \vp_{\ns - 1} \\
        \m{F} \vp_\ns
      \end{array}
    \right]}_{\displaystyle \mathbb{B}}$
  }
\end{equation}
where $\mathbb{A}$ is an $\nn \ns \times \nn \ns$ matrix, and $\mathbb{X}$ and
$\mathbb{B}$ are $\nn \ns$-element vectors.

The most direct way to solve the system in \eref{dynamic-steady-system} is to
use a dense solver, such as the \up{LU} decomposition \cite{press2007}. However,
since $\mathbb{A}$ is a sparse matrix, a more appropriate approach is to employ
a sparse solver, such as the unsymmetric multifrontal method \cite{davis2004}.
The computational complexity of such solutions is $\bigo{n_s^3 n_n^3}$
\cite{press2007} where $\nn$ is the number of nodes in the thermal \up{RC}
circuit, and $\ns$ is the number of samples in the power profile. The problem,
however, is that the system to solve can be extremely large, which is due
primarily to \ns. In such cases, direct solvers are prohibitively slow and
require an enormous amount of memory. Therefore, we do not discuss them any
further.

Another potential approach is leveraging iterative methods for solving systems
of linear equations, such as the Jacobi or Gauss--Seidel method
\cite{press2007}. Such methods are designed to overcome the problems of direct
solvers, and they are consequently applicable for very large systems. However,
the most important issue with these methods is their convergence. In our
experiments, we have not observed any advantages of using these methods compared
to the other techniques. Thus, they are excluded from further discussion.

Yet another solution can be obtained by observing that $\mathbb{A}$ in
\eref{dynamic-steady-system} is, in fact, a block Toeplitz matrix and, moreover,
a block-circulant matrix, in which each block row is rotated one block element
to the right relative to the preceding block row. This observation leads to a
range of possible techniques for solving the system of equations shown in
\eref{dynamic-steady-system}, such as the fast Fourier transform
\cite{mazancourt1983} used in the experiments reported in
\sref{dynamic-steady-results}.

The major problem with the aforementioned techniques is that \one~the sparseness
of $\mathbb{A}$ is not taken into account, or \two~the specific structure of
$\mathbb{A}$ is ignored, which results in inefficient and, in some cases,
inaccurate computations. Let us now develop a solution that does not have these
issues.

Have a careful look at the structure of $\mathbb{A}$ in
\eref{dynamic-steady-system}. The nonzero elements are located only on the block
diagonal, the subdiagonal attached to the block diagonal, and the superdiagonal
in the top-right corner of the matrix. Linear systems with similar structures
arise in boundary value problems of ordinary differential equations, and the
technique to solve them is to form a so-called condensed equation or condensed
system \cite{stoer2002}, as we describe next.

To begin with, let
\[
  \v{v}_i = \m{F} \vp_i
\]
for $i = \range{1}{\ns}$. \eref{transient-recurrence} can then be rewritten as
follows:
\begin{equation} \elab{dynamic-steady-recurrence}
  \vs_i = \m{E} \vs_{i - 1} + \v{v}_i
\end{equation}
for $i = \range{1}{\ns}$. Applying this formula recursively starting from
$\vs_0$ leads to
\[
  \vs_i = \m{E}^i \vs_0 + \v{w}_i
\]
for $i = \range{1}{\ns}$. In the above, $\v{w}_i$ is an auxiliary recurrence
defined by
\begin{equation} \elab{dynamic-steady-auxiliary-recurrence}
  \v{w}_i = \m{E} \v{w}_{i - 1} + \v{v}_i
\end{equation}
for $i = \range{1}{\ns}$ where
\[
  \v{w}_0 = \v{0}.
\]
After taking \ns steps, we arrive at the following state vector:
\[
  \vs_\ns = \m{E}^\ns \vs_0 + \v{w}_\ns.
\]
Taking into account the boundary condition given in
\eref{dynamic-steady-condition}, we obtain the following system of linear
equations:
\[
  (\m{I} - \m{E}^\ns) \vs_\ns = \v{w}_\ns.
\]
Since $\m{E}$ is the matrix exponential, which can be seen in
\eref{matrix-exponential}, the above system can be rewritten as follows:
\[
  (\m{I} - \m{U} e^{\m{\Lambda} \period} \transpose{\m{U}}) \vs_\ns = \v{w}_\ns
\]
where $\period = \ns \dt$ is the period of the power profile \mp. By splitting
the identity matrix $\m{I}$ into $\m{U} \transpose{\m{U}}$, we obtain the
following solution to the system:
\begin{align*}
  \vs_\ns
  & = \m{U} (\m{I} - e^{\m{\Lambda} \period})^{-1} \transpose{\m{U}} \v{w}_\ns \\
  & = \m{U} \: \diagonal{\frac{1}{1 - e^{\lambda_1 \period}}}{\frac{1}{1 - e^{\lambda_\ns \period}}} \transpose{\m{U}} \v{w}_\ns.
\end{align*}
The above equation yields not only the final state vector $\vs_\ns$ but also the
initial one $\vs_0$. Consequently, the rest of the state vectors $\set{\vs_i}_{i
= 1}^{\ns - 1}$ can be successively found by means of
\eref{dynamic-steady-recurrence} where each $\v{v}_i$ has already been
calculated when computing $\v{w}_\ns$. The last step of the solution is to
compute the actual dynamic steady-state temperature profile \mq by applying
\eref{temperature-algebraic}.

\inputalgorithm{dream-dynamic-steady-solution}
It can be seen that the solution to the $\nn \ns \times \nn \ns$ system in
\eref{dynamic-steady-system} has been reduced to the two trivial recurrences in
\eref{dynamic-steady-recurrence} and \eref{dynamic-steady-auxiliary-recurrence}
that traverse the \ns steps of the power profile \mp. The pseudocode for this
solution is given in \aref{dream-dynamic-steady-solution}, and its key aspects
are as follows.

Line~2--5: \eref{dynamic-steady-auxiliary-recurrence} is recursively evaluated
for all time steps of the input power profile \mp in order to calculate the
auxiliary vector $\v{w}_\ns$.

Line~6: The calculated $\v{w}_\ns$ is utilized in order to compute the final (or
initial) state vector $\vs_\ns$. This vector is stored in an $\nn \times \ns$
matrix denoted by $\m{S}$. Note that, for convenience, $\vs_\ns$ is stored in
the first column of $\m{S}$.

Line~7--9: Using $\vs_\ns$ or, equivalently, $\vs_0$,
\eref{dynamic-steady-recurrence} is recursively evaluated in order to calculate
the remaining state vectors, that is, $\set{\vs_i}_{i = 1}^{\ns - 1}$.

Line 10: \eref{temperature-algebraic} is applied in order to compute the desired
\mq.

It is worth noting that the auxiliary transformation presented in
\sref{transient-solution} and the accompanying eigendecomposition in
\eref{eigendecomposition} have substantially simplified the calculations
associated with dynamic steady-state analysis. Note also that the
eigendecomposition along with $\m{E}$ and $\m{F}$ are computed only once for a
particular thermal \up{RC} circuit and can be considered to be given together
with the circuit. In other words, these quantities stay the same when different
power profiles are to be analyzed, which is particularly advantageous when an
intensive design-space-exploration procedure is concerned.

The computational complexity of the whole procedure is estimated to be
\[
  \bigo{\ns n_n^2 + n_n^3}.
\]
The complexity is linear with respect to \ns, which is important, since \ns is
typically much larger than \nn, that is, the number of thermal nodes.

\subsection{\resultstitle}
\slab{dynamic-steady-results}

Let us assess the performance of the solution to dynamic steady-state analysis
proposed in \sref{dynamic-steady-solution}. All the experiments are conducted on
a \up{GNU}/Linux machine equipped with an Intel Core i7 3.4~\up{GH}z and
8~\up{GB} of \up{RAM}.

Thermal \up{RC} circuits are constructed by means of HotSpot \cite{skadron2003}
with its default configuration, and they follow the principle described in
\sref{temperature-model}. The sampling interval \dt of power and temperature
profiles is set to 1~ms.

For purposes of comparison, we consider two alternative techniques. Namely, we
use the one based on iterative transient analysis, which is introduced in
\sref{dynamic-steady-past}, and the one based on the fast Fourier transform,
which is mentioned in \sref{dynamic-steady-solution}, since they are comparable
with the proposed technique in terms of accuracy. In the case of transient
analysis, we evaluate both the fast analytical solution described in
\sref{transient-solution} and the one implemented in HotSpot, and the
corresponding iterative calculation is undertaken until the \ac{NRMSE} relative
to the dynamic steady-state temperature profile computed by means of the
proposed method, which is exact, is less than 1\%.

\inputfigure{dream-dynamic-steady-speed-steps}
First of all, we vary the period \period of power and temperature
profiles---and, therefore, the number of samples \ns that they contain---while
keeping the architecture fixed, which is a quad-core platform with a
processing-element area of 4~\power{mm}{2}. The results of this experiment are
depicted in \fref{dream-dynamic-steady-speed-steps} on a semilogarithmic scale.
It can be seen that the proposed technique is 9--170 times faster than iterative
transient analysis with the analytical solution and roughly 5000 times faster
than iterative transient analysis with HotSpot.

\inputfigure{dream-dynamic-steady-speed-elements}
In the second experiment, we evaluate the scaling properties of our method with
respect to the number of processing elements \np. The period is fixed to 500~ms,
which results in 500 time steps. The results are shown in
\fref{dream-dynamic-steady-speed-elements}. It can be observed that the proposed
technique provides a significant performance improvement relative to the
alternative solutions.
