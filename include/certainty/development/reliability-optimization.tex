In this section, we illustrate the importance of temperature analysis for
design-space exploration and, more specifically, for reliability optimization.

The impact of temperature on the lifetime of electronic systems is well known
\cite{srinivasan2004, coskun2006, xiang2010, jedec2016}. The failure mechanisms
that are commonly considered are electromigration, time-dependent dielectric
breakdown, and thermal cycling, which are directly driven by temperature
\cite{jedec2016}. Among these failure mechanisms, thermal cycling has arguably
the most prominent dependence on temperature: not only the average and maximum
temperature but also the amplitude and frequency of temperature oscillations
have a huge impact on the lifetime of the circuit. In this context, the
availability of detailed temperature profiles is essential. With these aspects
in mind, we focus our attention here on thermal cycling, which allows us to
demonstrate the utility of our solution to dynamic steady-state analysis
presented in \sref{dynamic-steady-state-solution} for mitigating the damage
caused by temperature oscillations. To this end, we develop a
thermal-cycling-aware technique for scheduling of periodic applications. Note
that, by exploring the design space looking for configurations that reduce the
system's wear, we implicitly account for performance uncertainty, which is
introduced in \cref{introduction}. However, this approach to performance
uncertainty is suboptimal, which it to be elaborated on and addressed in
\sref{chaos-reliability-analysis}.

In the remainder of the section, we first consider a motivational example,
\sref{thermal-cycling-example}. In \sref{thermal-cycling-problem}, we formulate
our optimization objective and, in \sref{thermal-cycling-solution}, describe the
optimization technique that we utilize in order to attain it. Lastly, the
experimental results are reported in \sref{thermal-cycling-results}.

\subsection{\exampletitle}
\slab{thermal-cycling-example}

\inputfigure{thermal-cycling-task-graph}
\inputfigure{thermal-cycling-example}
We begin by giving a motivational example. Consider a periodic application with
six tasks denoted by T1--T6 and a heterogeneous platform with two processing
elements denoted by P1 and P2. The task graph of the application is given in
\fref{thermal-cycling-task-graph} along with the execution times of the tasks
for both processing elements. The period of the application is 60~ms. The first
alternative schedule and the resulting dynamic steady-state temperature profile
are shown on the left-hand side of \fref{thermal-cycling-example} where the
height of a task represents its power consumption. It can be seen that P1 is
experiencing three thermal cycles, that is, there are three intervals wherein
temperature starts from a certain value, reaches an extremum, and then comes
back. If we move T6 to P2, the number of cycles decreases to two, which can be
seen in the middle of \fref{thermal-cycling-example}. If we also swap T2 and T4,
the number of cycles of P1 drops to one, which is depicted on the right-hand
side. According to the reliability model that we shall describe shortly, these
two changes improve the lifetime of the system by around 45\% and 55\%,
respectively, relative to the initial schedule.

The above example shows that, when exploring the design space, it is important
to take into consideration the number of temperature fluctuations as well as
their characteristics. In order to acquire this information, dynamic
steady-state temperature analysis has to be undertaken.

\subsection{\problemtitle}
\slab{thermal-cycling-problem}

A heterogeneous platform with \np processing elements is to execute a periodic
application with \nt tasks. The application is given as a directed acyclic graph
whose vertices and edges correspond to the tasks and to data dependencies
between these tasks, respectively; see \fref{thermal-cycling-task-graph} for an
example. The period of the application is denoted by \period and assumed to be
equal to the application's deadline. Furthermore, each pair of a task and a
processing element is characterized by an execution time and a power
consumption; these are the characteristics that the task has when it is assigned
to the processing element.

Since we are orientated toward the design stage in this context, static
scheduling is considered, which is a task that is typically done offline. The
application is assumed to be scheduled using a static cyclic scheduler following
the list scheduling policy \cite{adam1974}. The input to the scheduler is a
mapping of the tasks onto the processing elements and a set of priorities of the
tasks; other parameters are implicitly known to the scheduler. The schedule
produces a vector specifying the starting times of the tasks. Both the mapping
and starting times are referred to as a schedule, which we denote by \schedule.

The time to failure of each processing element is modeled using the reliability
model presented in \sref{thermal-cycling-fatigue}. Our optimization objective is
\begin{equation} \elab{thermal-cycling-objective}
  \max_{\schedule} \min_{i = 1}^\np \mean_i(\schedule)
\end{equation}
such that
\begin{align} \elab{thermal-cycling-constraints}
  \begin{split}
    & \period(\schedule) \leq \period_\maximum \text{ and} \\
    & Q(\schedule) \leq \q_\maximum.
  \end{split}
\end{align}
In the above formulae, $\mean_i$ is the \ac{MTTF} of processing element $i$
computed according to \eref{thermal-cycling-mean-time}; \period is the period of
the application; and
\[
  Q(\schedule) = \norm[\infty]{\mq(\schedule)}
\]
where \mq is the dynamic steady-state temperature profile of the system, and
$\norm[\infty]{\cdot}$ denotes the uniform norm. The first constraint in
\eref{thermal-cycling-constraints} enforces a deadline on the schedule while the
second constraint enforces a maximum temperature $\q_\maximum$ on the resulting
temperature profile \mq.

\subsection{\solutiontitle}
\slab{thermal-cycling-solution}

The optimization is undertaken using a genetic algorithm \cite{schmitz2004}. In
this paradigm inspired by biology, a population of chromosomes, which represent
candidate solutions, is carried through a number of generations in order to
produce a chromosome with the best possible fitness, that is, a solution that
maximizes the objective function. The fitness function in this case is
\eref{thermal-cycling-objective}.

Each chromosome contains $2 \nt$ genes---twice the number of tasks---and it can
be viewed as two concatenated vectors with \nt elements each. The first vector
is in $\{ \range{1}{\np} \}^\nt$, and it encodes a mapping of the tasks onto the
processing elements. The second vector is in $\{ \range{1}{\nt} \}^\nt$, and it
encodes priorities of the tasks. The usage of this information is to be
discussed shortly. The population contains $4 \nt$ chromosomes. In each
generation, a number of chromosomes are chosen for breeding by a tournament
selection with the number of competitors proportional to the population size.
The chosen chromosomes undergo a two-point crossover with probability 0.8 and a
uniform mutation with probability 0.01. The evolution mechanism follows the
elitism model where the best chromosome (solution) always survives. The stopping
condition is the absence of improvement within 200 successive generations.

The fitness of a chromosome is evaluated in a number of steps. First, the
chromosome is decoded, and the mapping of the tasks onto the processing elements
and their priorities are fed to the list scheduler. The scheduler produces a
schedule \schedule. If the schedule violates the deadline constraint given in
\eref{thermal-cycling-constraints}, the chromosome is penalized proportionally
to the amount of violation and is not further processed. Otherwise, based on the
parameters of the processing elements and tasks, a power profile \mp is
constructed, and the corresponding temperature profile \mq is computed using our
technique presented in \sref{dynamic-steady-state-solution}. If the profile
violates the temperature constraint in \eref{thermal-cycling-constraints}, the
chromosome is penalized proportionally to the amount of violation and is not
further processed. Otherwise, the \ac{MTTF} of each processing element is
estimated according to \eref{thermal-cycling-mean-time}, and the fitness
function in \eref{thermal-cycling-objective} is computed.

\subsection{\resultstitle}
\slab{thermal-cycling-results}

In this subsection, we proceed to the optimization itself. We shall first
consider a set of synthetic applications and then study a real-life one. The
general experimental setup is the same as the one described in
\sref{dynamic-steady-state-results}. All the configuration files used in the
experiments are available online at \cite{eslab2012}.

Heterogeneous platforms and periodic applications are generated randomly using
the \up{TGFF} tool \cite{dick1998} in such a way that the execution times of
tasks are uniformly distributed between 1 and 10~ms, and that the static power
accounts for 30--60\% of the total power consumption. The area of a processing
element is set to 4~mm\textsuperscript{2}. The modeling of the leakage power is
based on the linear approximation discussed in
\sref{power-temperature-interplay}. The maximum-temperature constraint
$\q_\maximum$ in \eref{thermal-cycling-constraints} is set to \celsius{100}. In
\eref{thermal-cycling-mean-cycles}, the Coffin--Manson exponent $b_i$ is set to
6, the activation energy $c_i$ to 0.5, and the elastic region $\Delta \q_{0,
ij}$ to 0 \cite{jedec2016}; the coefficient of proportionality $a_i$ in
\eref{thermal-cycling-mean-cycles} is irrelevant since we are concerned with
relative improvements, which will be explained shortly.

The initial population of chromosomes is initialized partially randomly and
partially based on a temperature-aware heuristic proposed in \cite{xie2006},
which we shall refer to as the initial solution. The heuristic relies on spatial
temperature variations and tries to minimize the maximum temperature while
satisfying real-time constraints. This solution is also used to decide on the
deadline constraint \period in \eref{thermal-cycling-constraints}: it is set to
the duration of the initial schedule extended by 5\%. Furthermore, the initial
solution serves as a baseline for evaluating the performance of the solutions
delivered by our optimization procedure.

\inputtable{thermal-cycling-elements}
In the first set of experiments, we change the number of processing elements \np
while keeping the number of tasks \nt per processing element constant and equal
to 20. For each problem, we generate 20 random task graphs and compute the
average change in the \ac{MTTF} relative to the initial solution. In addition,
we calculate the average change in the energy consumption. The obtained results
are reported in \tref{thermal-cycling-elements}, which also shows the average
time taken by the optimization procedure. It can be seen that the
reliability-aware optimization increases the \ac{MTTF} by a factor of 13--40.
Even for large problems---such as those with 16 processing elements executing
320 tasks---a feasible schedule that significantly improves the lifetime of the
system can be found in an affordable time. Moreover, as shown in
\tref{thermal-cycling-elements}, the performed optimization does not impact much
the energy efficiency of the system.

\inputtable{thermal-cycling-tasks}
In the second set of experiments, we keep the quad-core platform and vary the
number of tasks \nt of the application. As before, for each problem, we generate
20 random task graphs and monitor the changes in the \ac{MTTF} and energy
consumption relative to the initial solution. The results can be seen in
\tref{thermal-cycling-tasks}. The observations are similar to those made with
respect to \tref{thermal-cycling-elements}.

\inputtable{thermal-cycling-methods}
The experiments show that our optimization is able to effectively increase the
\ac{MTTF} of the system at hand. The efficiency is due to the fast and accurate
approach to dynamic steady-state temperature analysis presented in
\sref{dynamic-steady-state-solution}, which is at the heart of the optimization
procedure. Due to its speed, the technique allows a large portion of the design
space to be explored. In order to illustrate this, let us replace, inside the
optimization framework, our method with \one~the one based on iterative
transient analysis with HotSpot and \two~the one based on static steady-state
analysis; see \sref{dynamic-steady-state-prior}. The goal is to compare the
results in \tref{thermal-cycling-tasks} with the results produced by the two
alternative methods when they are given the same amount of time as the one taken
by our method. For each problem, the optimized \ac{MTTF} produced by either of
the two approximate methods is re-evaluated by our exact method. The results are
summarized in \tref{thermal-cycling-methods} where \ac{MTTF}\textsubscript{i}
and \ac{MTTF}\textsubscript{ii} stand for the two alternative methods,
respectively. It can be seen that, for example, the lifetime of the platform
running 160 tasks can be extended by a factor of 18 using our technique whereas
the best solutions found by the other two techniques within the same time frame
are only around 2--5 times better than the initial solution. The reason for the
poor performance of iterative transient analysis with HotSpot is the excessively
long execution time of the calculation of dynamic steady-state temperature
profiles, which means that this method allows for a very shallow exploration of
the design space. In the case of static steady-state analysis, the reason is
different: the method is fast but also very inaccurate as it is discussed and
illustrated in \sref{dynamic-steady-state-prior}. The inaccuracy drives the
optimization towards solutions that turn out to be of low quality.

\inputfigure{thermal-cycling-pareto}
The experiments show that the impact of the optimization on the energy
consumption is insignificant. This is not surprising: the optimization searches
toward low-temperature solutions, which are also implicitly the low-leakage
ones. In order to explore this further, let us perform a multi-objective
optimization along the dimensions of energy and reliability, and let us use
\up{NSGA-II} \cite{deb2002}. The resulting Pareto front averaged over 20
applications with 80 tasks deployed on a quad-core platform is displayed in
\fref{thermal-cycling-pareto}. It can be observed that the variation of the
energy change is less than 2\%. This means that the solutions optimized for the
\ac{MTTF} have an energy consumption that is almost identical to the one of the
solutions optimized for energy. At the same time, the difference along the
\ac{MTTF} dimension is huge. This means that ignoring the reliability aspect the
designer may end up with a significantly decreased \ac{MTTF} without any
significant gain in the energy consumption.

Finally, we consider a real-life application, namely, an \up{MPEG-2} decoder
\cite{ffmpeg}, which is assumed to be deployed on a dual-core platform. The
decoder is analyzed and split into 34 tasks. The parameters of each task are
obtained through a system-level simulation using \up{MPARM} \cite{benini2005}.
The deadline is set to 40~ms assuming 25 frames per second. The solution found
by the proposed method improves the lifetime of the system by a factor of 23.59
with a 5\% energy saving compared to the initial solution. The solutions found
by undertaking the same optimization via the two alternative methods mentioned
earlier are only 5.37 and 11.5 times better than the initial one, respectively.

To conclude, the experimental experiments have demonstrated the superiority of
the proposed approach to dynamic steady-state temperature analysis in the
context of reliability optimization compared to the state-of-the-art.
